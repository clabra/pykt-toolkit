{
  "defaults": {
    "model": "ikt",
    "dataset": "assist2015",
    "fold": 0,
    "seed": 42,
    "train_script": "examples/train_ikt.py",
    "eval_script": "examples/eval_ikt.py",
    "epochs": 30,
    "batch_size": 64,
    "learning_rate": 0.0001,
    "weight_decay": 1.7571e-05,
    "optimizer": "Adam",
    "gradient_clip": 1.0,
    "patience": 4,
    "monitor_freq": 50,
    "use_amp": false,
    "use_wandb": false,
    "auto_shifted_eval": true,
    "seq_len": 200,
    "d_model": 256,
    "n_heads": 4,
    "num_encoder_blocks": 8,
    "d_ff": 1536,
    "dropout": 0.2,
    "emb_type": "qid",
    "lambda_bce": 0.5,
    "epsilon": 0.05,
    "phase": null,
    "rasch_path": null,
    "mastery_method": "bkt",
    "num_trajectories": 10,
    "min_trajectory_steps": 10
  },
  "types": {
    "launcher": [
      "train_script",
      "eval_script"
    ],
    "data": [
      "dataset",
      "fold"
    ],
    "runtime": [
      "seed",
      "epochs",
      "batch_size",
      "learning_rate",
      "weight_decay",
      "optimizer",
      "gradient_clip",
      "patience",
      "monitor_freq",
      "use_amp",
      "use_wandb",
      "auto_shifted_eval",
      "num_trajectories",
      "min_trajectory_steps"
    ],
    "model_config": [
      "seq_len",
      "d_model",
      "n_heads",
      "num_encoder_blocks",
      "d_ff",
      "dropout",
      "emb_type"
    ],
    "loss_weights": [
      "lambda_bce",
      "epsilon"
    ],
    "training_phase": [
      "phase"
    ],
    "data_paths": [
      "rasch_path"
    ]
  },
  "fixed": {
    "lambda_constraint": {
      "value": "lambda_mastery = 1.0 - lambda_bce",
      "rationale": "iKT SINGLE-ENCODER ARCHITECTURE (2025-11-27): Multi-task loss weights must sum to 1.0. Two losses: L1 (BCE), L2 (Rasch). lambda_mastery is auto-computed as 1.0 - lambda_bce. Two-phase training: Phase 1 (L_total = L2, epsilon=0), Phase 2 (L_total = lambda_bce * L1 + lambda_mastery * L2, epsilon>0). Epsilon controls tolerance for Rasch deviation in Phase 2.",
      "validated_by_experiments": []
    }
  },
  "md5": "bce34e59a26292ebcc2523f34af0b577"
}