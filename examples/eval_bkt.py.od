"""
Compute BKT Validation Correlation

This script calculates the correlation between model mastery estimates (M_IRT)
and BKT mastery trajectories P(L_t) to validate the model against a dynamic baseline.

Usage:
    python examples/compute_bkt_correlation.py \
        --experiment_dir experiments/20251128_232738_ikt2_irt-baseline_400293 \
        --dataset assist2015 \
        --output_file bkt_validation.json
"""

import argparse
import json
import pickle
import numpy as np
import pandas as pd
import torch
from scipy.stats import pearsonr
from pathlib import Path
import os
import sys

#sys.path.insert(0, '/home/conchalabra/projects/dl/pykt-toolkit')

from pykt.models import evaluate, init_model
from pykt.datasets import init_dataset4train
from torch.utils.data import DataLoader
from pykt.datasets.data_loader import KTDataset
from pykt.utils import set_seed


def load_bkt_parameters(dataset, bkt_path=None):
    """
    Load pre-calculated BKT parameters.
    
    Args:
        dataset: Dataset name (used for default path)
        bkt_path: Path to BKT targets file (default from configs/parameter_default.json)
    
    Returns:
        tuple: (bkt_params_dict, metadata_dict)
    
    Raises:
        FileNotFoundError: If BKT file not found
        ValueError: If file format is invalid (missing required keys)
    """
    if bkt_path is None:
        bkt_path = Path(f"data/{dataset}/bkt_mastery_states.pkl")
    else:
        bkt_path = Path(bkt_path)
    
    if not bkt_path.exists():
        raise FileNotFoundError(
            f"BKT parameters not found at {bkt_path}. "
            f"Run: python examples/train_bkt.py --dataset {dataset}"
        )
    
    try:
        with open(bkt_path, 'rb') as f:
            bkt_data = pickle.load(f)
    except Exception as e:
        raise RuntimeError(
            f"Failed to load BKT data from {bkt_path}: {e}"
        ) from e
    
    # Validate required format
    if 'bkt_params' not in bkt_data:
        raise ValueError(
            f"Invalid BKT file format at {bkt_path}: missing 'bkt_params' key.\n"
            f"Expected format: {{'bkt_params': dict, 'bkt_targets': dict, 'metadata': dict}}\n"
            f"Found keys: {list(bkt_data.keys())}"
        )
    
    bkt_params = bkt_data['bkt_params']
    
    # Validate bkt_params structure (each skill should have 4 parameters)
    if bkt_params:
        first_skill = next(iter(bkt_params.values()))
        required_keys = {'prior', 'learns', 'slips', 'guesses'}
        if not required_keys.issubset(first_skill.keys()):
            raise ValueError(
                f"Invalid BKT parameters format at {bkt_path}.\n"
                f"Each skill must have keys: {required_keys}\n"
                f"Found keys in first skill: {set(first_skill.keys())}"
            )
    
    return bkt_params, bkt_data.get('metadata', {})


def evaluate (bkt_path): 
    """
    Claculate evaluation metrics
    
    Args:
        bkt_path: Path to BKT targets file (default from data/[dataset_name]/bkt_targets_mono.pkl

    Returns: 
        results: Dictionary containing correlation metrics
        bkt_params: Dictionary containing BKT parameters
        bkt_metadata: Dictionary containing BKT metadata
        df: DataFrame containing model mastery estimates
        experiment_dir: Path to experiment directory

    """

    print("="*80)
    print("BKT EVALUATION")
    print("="*80)
    
    # Load data
    
    bkt_file = bkt_path if bkt_path else f"data/{dataset}/bkt_mastery_state_mono.pkl"
    print(f"\n1. Loading BKT parameters from {bkt_file}...")
    bkt_params, bkt_metadata = load_bkt_parameters(dataset, bkt_file)
    print(f"   Loaded BKT parameters for {len(bkt_params)} skills")
    if bkt_metadata:
        print(f"   BKT metadata: {bkt_metadata}")
    
    print(f"\n2. Loading model mastery estimates from {experiment_dir}...")
    df = load_model_mastery(bkt_file)
    print(f"   Loaded {len(df)} interactions")
    print(f"   Students: {df['student_id'].nunique()}")
    print(f"   Skills: {df['skill_id'].nunique()}")
    
    # Validate data consistency
    validate_data_consistency(experiment_dir, dataset, bkt_metadata, df)
    
    # Compute BKT forward inference for model interactions
    print(f"\n3. Computing BKT forward inference P(L_t) for interactions...")
    print(f"   Running BKT forward algorithm on test data...")
    bkt_mastery = compute_bkt_mastery(bkt_params, df)
    
    # Get model mastery (M_IRT from mi_value column)
    model_mastery = df['mi_value'].values
    
    # Remove NaN values
    valid_mask = ~(np.isnan(bkt_mastery) | np.isnan(model_mastery))
    bkt_mastery_clean = bkt_mastery[valid_mask]
    model_mastery_clean = model_mastery[valid_mask]
    
    print(f"   Valid interactions: {len(model_mastery_clean)} / {len(df)}")
    
    if len(model_mastery_clean) < 10:
        raise ValueError("Too few valid interactions for correlation calculation")
    
    # Compute standard correlation
    print(f"\n4. Computing Pearson correlation...")
    correlation, p_value = pearsonr(model_mastery_clean, bkt_mastery_clean)
    
    # Compute supplementary correlations
    print(f"\n5. Computing supplementary correlations...")
    
    # Time-lagged correlation (attempt > 3, optimal threshold)
    print(f"   a) Time-lagged correlation (attempt > 3)...")
    time_lagged_r, time_lagged_p, time_lagged_n = compute_time_lagged_correlation(
        df, bkt_mastery, model_mastery, min_attempt=3, strict=True
    )
    
    if time_lagged_r is not None:
        print(f"      r = {time_lagged_r:.4f} (n = {time_lagged_n})")
    else:
        print(f"      Insufficient data for time-lagged correlation")
    
    # Trajectory slope correlation
    print(f"   b) Trajectory slope correlation...")
    slope_result = compute_trajectory_slopes(df, bkt_mastery, model_mastery)
    
    if slope_result[0] is not None:
        slope_r, slope_p, slope_n = slope_result
        print(f"      r = {slope_r:.4f} (n = {slope_n} trajectories)")
    else:
        slope_r, slope_p, slope_n = None, None, 0
        print(f"      Insufficient data for trajectory correlation")
    
    # Compute error statistics
    mse = np.mean((model_mastery_clean - bkt_mastery_clean) ** 2)
    mae = np.mean(np.abs(model_mastery_clean - bkt_mastery_clean))
    
    model_mean = np.mean(model_mastery_clean)
    model_std = np.std(model_mastery_clean)
    bkt_mean = np.mean(bkt_mastery_clean)
    bkt_std = np.std(bkt_mastery_clean)
    
    # Prepare results
    results = {
        "bkt_correlation": float(correlation),
        "p_value": float(p_value),
        "mse": float(mse),
        "mae": float(mae),
        "num_interactions": int(len(model_mastery_clean)),
        "num_students": int(df['student_id'].nunique()),
        "num_skills": int(df['skill_id'].nunique()),
        "bkt_mastery_stats": {
            "mean": float(bkt_mean),
            "std": float(bkt_std),
            "min": float(np.min(bkt_mastery_clean)),
            "max": float(np.max(bkt_mastery_clean))
        },
        "metadata": {
            "experiment_dir": str(experiment_dir),
            "dataset": dataset,
            "bkt_targets_file": str(bkt_path) if bkt_path else f"data/{dataset}/bkt_mastery_states.pkl",
            "bkt_metadata": bkt_metadata,
            "validation_passed": True
        }
    }
    
    # Print results
    print("\n" + "="*80)
    print("RESULTS")
    print("="*80)
    
    print(f"\nDISTRIBUTION STATISTICS:")
    print(f"  Model M_IRT:  mean={model_mean:.4f}, std={model_std:.4f}")
    print(f"  BKT P(L_t):   mean={bkt_mean:.4f}, std={bkt_std:.4f}")
    print(f"\nDATA SUMMARY:")
    print(f"  Interactions: {len(model_mastery_clean):,}")
    print(f"  Students:     {df['student_id'].nunique()}")
    print(f"  Skills:       {df['skill_id'].nunique()}")


    
    # Save results
    if output_file:
        output_path = Path(experiment_dir) / output_file
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nResults saved to: {output_path}")
    
    return results

'''
def load_model_mastery(experiment_dir):
    """Load model mastery estimates from evaluation results."""
    mastery_path = Path(experiment_dir) / "mastery_test.csv"
    
    if not mastery_path.exists():
        raise FileNotFoundError(
            f"Model mastery file not found at {mastery_path}. "
            f"Ensure evaluation was run with mastery tracking enabled."
        )
    
    df = pd.read_csv(mastery_path)
    return df
'''

'''
def validate_data_consistency(experiment_dir, dataset, bkt_metadata, df):
    """
    Validate that BKT parameters were computed on compatible data split.
    
    Args:
        experiment_dir: Path to experiment directory
        dataset: Dataset name
        bkt_metadata: Metadata from BKT targets file
        df: DataFrame with model mastery estimates
        
    Raises:
        ValueError: If data splits are incompatible
    """
    print(f"\n   Validating data consistency...")
    
    # Load experiment config to check fold and data split
    config_path = Path(experiment_dir) / "config.json"
    if config_path.exists():
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        # Check dataset matches (try multiple config locations)
        config_dataset = (
            config.get('dataset') or 
            config.get('defaults', {}).get('dataset') or 
            config.get('experiment', {}).get('dataset') or
            'unknown'
        )
        
        if config_dataset != dataset and config_dataset != 'unknown':
            raise ValueError(
                f"Dataset mismatch: experiment uses '{config_dataset}' "
                f"but you specified BKT for '{dataset}'"
            )
        
        # Check fold if specified (try multiple config locations)
        experiment_fold = (
            config.get('fold') or
            config.get('defaults', {}).get('fold') or
            config.get('experiment', {}).get('fold')
        )
        bkt_fold = bkt_metadata.get('fold', None)
        
        # BKT should be trained on train+valid data, not test
        # So we only warn if BKT was computed on a specific test fold
        if bkt_fold is not None and bkt_fold == experiment_fold:
            print(f"   ⚠️  WARNING: BKT fold ({bkt_fold}) matches experiment fold ({experiment_fold})")
            print(f"       BKT should be trained on train+valid, not test data!")
            print(f"       Correlation may be inflated due to data leakage.")
    
    # Check that BKT has parameters for skills in test set
    test_skills = set(df['skill_id'].unique())
    bkt_skills = set(bkt_metadata.get('skill_ids', range(bkt_metadata.get('num_skills', 0))))
    
    missing_skills = test_skills - bkt_skills
    if missing_skills:
        raise ValueError(
            f"BKT parameters missing for {len(missing_skills)} skills in test set: "
            f"{sorted(missing_skills)[:10]}{'...' if len(missing_skills) > 10 else ''}\n"
            f"BKT must be trained on data containing all test skills."
        )
    
    # Check student overlap (warning only, not error)
    test_students = set(df['student_id'].unique())
    bkt_students = set(bkt_metadata.get('student_ids', []))
    
    if bkt_students:  # Only check if metadata contains student IDs
        overlap = test_students & bkt_students
        if overlap:
            print(f"   ⚠️  WARNING: {len(overlap)}/{len(test_students)} test students were in BKT training data")
            print(f"       This may inflate correlation. BKT should be trained on separate data split.")
        else:
            print(f"   ✓ No student overlap between BKT training and test set (good!)")
    
    print(f"   ✓ All test skills ({len(test_skills)}) have BKT parameters")
'''

'''
def compute_trajectory_slopes(df, bkt_mastery, model_mastery):
    """
    Compute learning trajectory slopes for each student-skill pair.
    
    Slope = (mastery_final - mastery_initial) / num_attempts
    
    Returns correlation between BKT slopes and model slopes.
    """
    # Group by student and skill
    trajectories = {}
    
    for idx, row in df.iterrows():
        key = (int(row['student_id']), int(row['skill_id']))
        
        if key not in trajectories:
            trajectories[key] = {
                'bkt_values': [],
                'model_values': [],
                'time_steps': []
            }
        
        trajectories[key]['bkt_values'].append(bkt_mastery[idx])
        trajectories[key]['model_values'].append(model_mastery[idx])
        trajectories[key]['time_steps'].append(row['time_step'])
    
    # Compute slopes for trajectories with multiple points
    bkt_slopes = []
    model_slopes = []
    
    for key, traj in trajectories.items():
        if len(traj['bkt_values']) >= 2:
            # Compute slope: (final - initial) / time_span
            bkt_slope = (traj['bkt_values'][-1] - traj['bkt_values'][0]) / len(traj['bkt_values'])
            model_slope = (traj['model_values'][-1] - traj['model_values'][0]) / len(traj['model_values'])
            
            bkt_slopes.append(bkt_slope)
            model_slopes.append(model_slope)
    
    if len(bkt_slopes) < 10:
        return None, 0, 0  # Not enough trajectories
    
    correlation, p_value = pearsonr(bkt_slopes, model_slopes)
    return correlation, p_value, len(bkt_slopes)
'''

'''
def compute_time_lagged_correlation(df, bkt_mastery, model_mastery, min_attempt=3, strict=False):
    """
    Compute correlation only for interactions after min_attempt.
    
    This reduces the bias from prior initialization effects.
    
    Args:
        min_attempt: Minimum attempt threshold (default: 3)
        strict: If True, uses > (strictly greater), if False uses >= (default: False)
    """
    # Track attempt number per student-skill
    attempt_counts = {}
    valid_indices = []
    
    for idx, row in df.iterrows():
        key = (int(row['student_id']), int(row['skill_id']))
        
        if key not in attempt_counts:
            attempt_counts[key] = 0
        attempt_counts[key] += 1
        
        # Include based on threshold
        if strict:
            if attempt_counts[key] > min_attempt:
                valid_indices.append(idx)
        else:
            if attempt_counts[key] >= min_attempt:
                valid_indices.append(idx)
    
    if len(valid_indices) < 10:
        return None, 0, 0  # Not enough data
    
    # Compute correlation on filtered data
    bkt_filtered = bkt_mastery[valid_indices]
    model_filtered = model_mastery[valid_indices]
    
    correlation, p_value = pearsonr(model_filtered, bkt_filtered)
    return correlation, p_value, len(valid_indices)
'''

def predict_bkt_mastery(user_id, skill_id, params):
    """
    Estimates mastery probability P(L_t) for the given student interaction.
    

    """
    

    return mastery_value

'''
def compute_bkt_correlation(experiment_dir, dataset, output_file=None, bkt_path=None):
    """
    Compute correlation between model mastery (M_IRT) and BKT mastery P(L_t).
    
    Includes:
    - Standard correlation (full data)
    - Time-lagged correlation (attempt >= 3, reduces prior bias)
    - Trajectory slope correlation (compares learning rates)
    
    Args:
        experiment_dir: Path to experiment directory with mastery_test.csv
        dataset: Dataset name (e.g., 'assist2015')
        output_file: Optional output JSON file for results
        bkt_path: Optional path to BKT targets file (default: data/{dataset}/bkt_mastery_states.pkl)
        
    Returns:
        dict: Results including multiple correlations, statistics, and metadata
    """
    print("="*80)
    print("BKT VALIDATION CORRELATION")
    print("="*80)
    
    # Load data
    bkt_file = bkt_path if bkt_path else f"data/{dataset}/bkt_mastery_states.pkl"
    print(f"\n1. Loading BKT parameters from {bkt_file}...")
    bkt_params, bkt_metadata = load_bkt_parameters(dataset, bkt_path)
    print(f"   Loaded BKT parameters for {len(bkt_params)} skills")
    if bkt_metadata:
        print(f"   BKT metadata: {bkt_metadata}")
    
    print(f"\n2. Loading model mastery estimates from {experiment_dir}...")
    df = load_model_mastery(experiment_dir)
    print(f"   Loaded {len(df)} interactions")
    print(f"   Students: {df['student_id'].nunique()}")
    print(f"   Skills: {df['skill_id'].nunique()}")
    
    # Validate data consistency
    validate_data_consistency(experiment_dir, dataset, bkt_metadata, df)
    
    # Compute BKT forward inference for model interactions
    print(f"\n3. Computing BKT forward inference P(L_t) for interactions...")
    print(f"   Running BKT forward algorithm on test data...")
    bkt_mastery = compute_bkt_mastery(bkt_params, df)
    
    # Get model mastery (M_IRT from mi_value column)
    model_mastery = df['mi_value'].values
    
    # Remove NaN values
    valid_mask = ~(np.isnan(bkt_mastery) | np.isnan(model_mastery))
    bkt_mastery_clean = bkt_mastery[valid_mask]
    model_mastery_clean = model_mastery[valid_mask]
    
    print(f"   Valid interactions: {len(model_mastery_clean)} / {len(df)}")
    
    if len(model_mastery_clean) < 10:
        raise ValueError("Too few valid interactions for correlation calculation")
    
    # Compute standard correlation
    print(f"\n4. Computing Pearson correlation...")
    correlation, p_value = pearsonr(model_mastery_clean, bkt_mastery_clean)
    
    # Compute supplementary correlations
    print(f"\n5. Computing supplementary correlations...")
    
    # Time-lagged correlation (attempt > 3, optimal threshold)
    print(f"   a) Time-lagged correlation (attempt > 3)...")
    time_lagged_r, time_lagged_p, time_lagged_n = compute_time_lagged_correlation(
        df, bkt_mastery, model_mastery, min_attempt=3, strict=True
    )
    
    if time_lagged_r is not None:
        print(f"      r = {time_lagged_r:.4f} (n = {time_lagged_n})")
    else:
        print(f"      Insufficient data for time-lagged correlation")
    
    # Trajectory slope correlation
    print(f"   b) Trajectory slope correlation...")
    slope_result = compute_trajectory_slopes(df, bkt_mastery, model_mastery)
    
    if slope_result[0] is not None:
        slope_r, slope_p, slope_n = slope_result
        print(f"      r = {slope_r:.4f} (n = {slope_n} trajectories)")
    else:
        slope_r, slope_p, slope_n = None, None, 0
        print(f"      Insufficient data for trajectory correlation")
    
    # Compute error statistics
    mse = np.mean((model_mastery_clean - bkt_mastery_clean) ** 2)
    mae = np.mean(np.abs(model_mastery_clean - bkt_mastery_clean))
    
    model_mean = np.mean(model_mastery_clean)
    model_std = np.std(model_mastery_clean)
    bkt_mean = np.mean(bkt_mastery_clean)
    bkt_std = np.std(bkt_mastery_clean)
    
    # Prepare results
    results = {
        "bkt_correlation": float(correlation),
        "p_value": float(p_value),
        "mse": float(mse),
        "mae": float(mae),
        "num_interactions": int(len(model_mastery_clean)),
        "num_students": int(df['student_id'].nunique()),
        "num_skills": int(df['skill_id'].nunique()),
        "supplementary_correlations": {
            "time_lagged": {
                "correlation": float(time_lagged_r) if time_lagged_r is not None else None,
                "p_value": float(time_lagged_p) if time_lagged_p is not None else None,
                "num_interactions": int(time_lagged_n),
                "min_attempt": 3,
                "operator": ">",
                "description": "Correlation after initialization (attempt > 3, optimal threshold)"
            },
            "trajectory_slopes": {
                "correlation": float(slope_r) if slope_r is not None else None,
                "p_value": float(slope_p) if slope_p is not None else None,
                "num_trajectories": int(slope_n),
                "description": "Correlation of learning rates (removes initialization bias)"
            }
        },
        "model_mastery_stats": {
            "mean": float(model_mean),
            "std": float(model_std),
            "min": float(np.min(model_mastery_clean)),
            "max": float(np.max(model_mastery_clean))
        },
        "bkt_mastery_stats": {
            "mean": float(bkt_mean),
            "std": float(bkt_std),
            "min": float(np.min(bkt_mastery_clean)),
            "max": float(np.max(bkt_mastery_clean))
        },
        "metadata": {
            "experiment_dir": str(experiment_dir),
            "dataset": dataset,
            "bkt_targets_file": str(bkt_path) if bkt_path else f"data/{dataset}/bkt_mastery_states.pkl",
            "bkt_metadata": bkt_metadata,
            "validation_passed": True
        }
    }
    
    # Print results
    print("\n" + "="*80)
    print("RESULTS")
    print("="*80)
    print(f"\nPRIMARY CORRELATION (standard BKT):")
    print(f"  r = {correlation:.4f}  (p = {p_value:.4e})")
    print(f"  MSE: {mse:.4f}")
    print(f"  MAE: {mae:.4f}")
    
    print(f"\nSUPPLEMENTARY CORRELATIONS:")
    if time_lagged_r is not None:
        print(f"  Time-lagged (attempt > 3):")
        print(f"    r = {time_lagged_r:.4f}  (p = {time_lagged_p:.4e})")
        print(f"    n = {time_lagged_n} interactions ({100*time_lagged_n/len(model_mastery_clean):.1f}% of data)")
        improvement = time_lagged_r - correlation
        print(f"    Improvement: {improvement:+.4f} ({100*improvement/abs(correlation):+.1f}%)")
    else:
        print(f"  Time-lagged: Insufficient data")
    
    if slope_r is not None:
        print(f"  Trajectory slopes (learning rates):")
        print(f"    r = {slope_r:.4f}  (p = {slope_p:.4e})")
        print(f"    n = {slope_n} student-skill trajectories")
    else:
        print(f"  Trajectory slopes: Insufficient data")
    
    print(f"\nDISTRIBUTION STATISTICS:")
    print(f"  Model M_IRT:  mean={model_mean:.4f}, std={model_std:.4f}")
    print(f"  BKT P(L_t):   mean={bkt_mean:.4f}, std={bkt_std:.4f}")
    print(f"\nDATA SUMMARY:")
    print(f"  Interactions: {len(model_mastery_clean):,}")
    print(f"  Students:     {df['student_id'].nunique()}")
    print(f"  Skills:       {df['skill_id'].nunique()}")
    
    # Interpretation
    print("\n" + "="*80)
    print("INTERPRETATION")
    print("="*80)
    
    print(f"\nPRIMARY CORRELATION (r = {correlation:.4f}):")
    if correlation > 0.8:
        interpretation = "STRONG alignment with BKT"
    elif correlation > 0.6:
        interpretation = "MODERATE alignment with BKT"
    elif correlation > 0.4:
        interpretation = "WEAK alignment with BKT"
    else:
        interpretation = "POOR alignment with BKT"
    print(f"  {interpretation}")
    
    if time_lagged_r is not None and time_lagged_r > correlation:
        print(f"\nTIME-LAGGED CORRELATION (r = {time_lagged_r:.4f}, attempt > 3):")
        print(f"  Correlation IMPROVES after initialization phase")
        print(f"  This indicates that prior mismatch (BKT P(L_0)=0.63 vs iKT2 learned)")
        print(f"  affects early interactions but both models align on learning dynamics")
        print(f"  Note: Threshold > 3 (not >= 3) provides optimal balance of correlation and sample size")
    
    if slope_r is not None:
        print(f"\nTRAJECTORY SLOPES (r = {slope_r:.4f}):")
        if slope_r > correlation:
            print(f"  Learning RATES correlate better than absolute mastery")
            print(f"  Validates that both models capture similar learning patterns")
            print(f"  Prior-independent metric confirms dynamic alignment")
        else:
            print(f"  Learning rates show similar correlation to absolute values")
    
    print(f"\nOVERALL VALIDATION:")
    print(f"  Standard correlation validates alignment with BKT theory")
    print(f"  Supplementary metrics provide deeper insight into dynamics")
    print(f"  Multiple correlations strengthen interpretability claims")
    
    # Save results
    if output_file:
        output_path = Path(experiment_dir) / output_file
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nResults saved to: {output_path}")
    
    return results
'''

'''
def update_metrics_csv(experiment_dir, results):
    """Update metrics_test.csv with BKT correlation columns."""
    import pandas as pd
    from pathlib import Path
    
    csv_path = Path(experiment_dir) / 'metrics_test.csv'
    
    if not csv_path.exists():
        print(f"\n⚠ Warning: {csv_path} not found, skipping CSV update")
        return
    
    try:
        df = pd.read_csv(csv_path)
        standard_corr = results['bkt_correlation']
        timelagged_corr = results['supplementary_correlations']['time_lagged']['correlation']
        df['bkt_correlation_standard'] = standard_corr
        df['bkt_correlation_timelagged'] = timelagged_corr
        df.to_csv(csv_path, index=False)
        print(f"\n✓ Updated {csv_path} with BKT correlations")
        print(f"  - bkt_correlation_standard={standard_corr:.6f}")
        print(f"  - bkt_correlation_timelagged={timelagged_corr:.6f}")
    except Exception as e:
        print(f"\n⚠ Warning: Could not update metrics_test.csv: {e}")
'''

def main():

    '''
    parser = argparse.ArgumentParser(
        description="Compute BKT validation correlation for iKT model"
    )

    parser.add_argument(
        "--experiment_dir",
        type=str,
        required=True,
        help="Path to experiment directory containing mastery_test.csv"
    )
    parser.add_argument(
        "--dataset",
        type=str,
        required=True,
        help="Dataset name (e.g., assist2015)"
    )
    parser.add_argument(
        "--output_file",
        type=str,
        default="bkt_validation.json",
        help="Output JSON filename (saved in experiment_dir)"
    )
    parser.add_argument(
        "--bkt_path",
        type=str,
        default=None,
        help="Path to BKT targets file (default: data/{dataset}/bkt_mastery_states.pkl, use bkt_mastery_states_mono.pkl for monotonic)"
    )
    
    parser.add_argument(
        "--update_csv",
        action='store_true',
        help="Update metrics_test.csv with correlations (default: True)"
    )
    '''

    args = parser.parse_args()
    
    results = compute_bkt_correlation(
        experiment_dir=args.experiment_dir,
        dataset=args.dataset,
        output_file=args.output_file,
        bkt_path=args.bkt_path
    )
    
    # Update metrics_test.csv by default
    if args.update_csv or args.update_csv is None:
        update_metrics_csv(args.experiment_dir, results)

'''
def update_metrics_csv(experiment_dir, results):
    """Update metrics_test.csv with BKT correlation columns."""
    import pandas as pd
    from pathlib import Path
    
    csv_path = Path(experiment_dir) / 'metrics_test.csv'
    
    if not csv_path.exists():
        print(f"\n⚠ Warning: {csv_path} not found, skipping CSV update")
        return
    
    try:
        df = pd.read_csv(csv_path)
        standard_corr = results['bkt_correlation']
        timelagged_corr = results['supplementary_correlations']['time_lagged']['correlation']
        df['bkt_correlation_standard'] = standard_corr
        df['bkt_correlation_timelagged'] = timelagged_corr
        df.to_csv(csv_path, index=False)
        print(f"\n✓ Updated {csv_path} with BKT correlations")
        print(f"  - bkt_correlation_standard={standard_corr:.6f}")
        print(f"  - bkt_correlation_timelagged={timelagged_corr:.6f}")
    except Exception as e:
        print(f"\n⚠ Warning: Could not update metrics_test.csv: {e}")
'''

if __name__ == "__main__":
    main()
