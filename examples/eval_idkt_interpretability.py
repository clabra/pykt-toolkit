#!/usr/bin/env python3
"""
Evaluation script for iDKT interpretability (alignment with BKT reference model).
"""

import os
import sys
import argparse
import json
import torch
import numpy as np
import pandas as pd
from scipy.stats import pearsonr
import pickle

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from pykt.models import init_model
from pykt.datasets import init_dataset4train
from pykt.utils import set_seed

device = "cpu" if not torch.cuda.is_available() else "cuda"

def parse_args():
    parser = argparse.ArgumentParser(description="Evaluate iDKT interpretability alignment")
    
    parser.add_argument("--checkpoint", type=str, required=True)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--dataset", type=str, required=True)
    parser.add_argument("--fold", type=int, required=True)
    parser.add_argument("--batch_size", type=int, default=32)
    
    # Architecture
    parser.add_argument("--d_model", type=int, default=256)
    parser.add_argument("--d_ff", type=int, default=512)
    parser.add_argument("--n_heads", type=int, default=8)
    parser.add_argument("--n_blocks", type=int, default=4)
    parser.add_argument("--dropout", type=float, default=0.2)
    parser.add_argument("--emb_type", type=str, default="qid")
    parser.add_argument("--final_fc_dim", type=int, default=512)
    parser.add_argument("--l2", type=float, default=1e-5)
    parser.add_argument("--seq_len", type=int, default=200)
    
    return parser.parse_args()

def main():
    args = parse_args()
    set_seed(42)
    
    # Load data config
    config_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../configs/data_config.json'))
    with open(config_path, 'r') as f:
        data_config = json.load(f)
    
    # Add absolute paths
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    for ds in data_config:
        if 'dpath' in data_config[ds]:
            dpath = data_config[ds]['dpath']
            if dpath.startswith('../'):
                data_config[ds]['dpath'] = os.path.abspath(os.path.join(project_root, dpath.replace('../', '')))
            else:
                data_config[ds]['dpath'] = os.path.abspath(os.path.join(project_root, dpath))

    # Load BKT parameters
    bkt_params_path = os.path.join(data_config[args.dataset]['dpath'], 'bkt_skill_params.pkl')
    with open(bkt_params_path, 'rb') as f:
        bkt_skill_params = pickle.load(f)

    # Load Augmented Test Data
    # NOTE: We assume evaluate script normally uses test_file, but for interpretability we need BKT columns.
    # We'll use the train_valid_file_bkt.csv for now as a proxy if test_bkt.csv doesn't exist.
    # Actually, let's just use the validation loader from init_dataset4train which we know is augmented.
    
    dpath = data_config[args.dataset]['dpath']
    orig_file = data_config[args.dataset]['train_valid_file']
    data_config[args.dataset]['train_valid_file'] = orig_file.replace('.csv', '_bkt.csv')
    
    _, valid_loader = init_dataset4train(args.dataset, 'idkt', data_config, args.fold, args.batch_size)

    # Init Model
    model_config = {
        'd_model': args.d_model, 'd_ff': args.d_ff, 'num_attn_heads': args.n_heads,
        'n_blocks': args.n_blocks, 'dropout': args.dropout, 'final_fc_dim': args.final_fc_dim, 'l2': args.l2
    }
    model = init_model('idkt', model_config, data_config[args.dataset], args.emb_type)
    model.load_state_dict(torch.load(args.checkpoint, map_location=device))
    model.to(device)
    model.eval()

    all_idkt_p = []
    all_bkt_p = []
    all_idkt_initmastery = []
    all_bkt_initmastery = []
    all_idkt_rate = []
    all_bkt_rate = []
    
    # Interaction-level records for heatmap
    param_records = []     # Static Parameters (L0 vs L0)
    traj_records = []      # Dynamic Trajectories (Pred vs Pred)
    max_export_students = 1000 # Limit to avoid massive CSVs

    print("Running inference for interpretability alignment...")
    with torch.no_grad():
        for data in valid_loader:
            q, c, r = data["qseqs"].to(device), data["cseqs"].to(device), data["rseqs"].to(device)
            qshft, cshft, rshft = data["shft_qseqs"].to(device), data["shft_cseqs"].to(device), data["shft_rseqs"].to(device)
            sm = data["smasks"].to(device)
            uids = data["uids"]
            
            # Augmented ground truth
            bkt_p_batch = data["bkt_p_correct"].to(device)
            bkt_im_batch = data["bkt_mastery"].to(device)
            
            # Forward pass
            cc_full = torch.cat((c[:,0:1], cshft), dim=1)
            cr_full = torch.cat((r[:,0:1], rshft), dim=1)
            cq_full = torch.cat((q[:,0:1], qshft), dim=1)
            
            y, initmastery, rate, _ = model(cc_full.long(), cr_full.long(), cq_full.long())
            
            # Collect aggregated metrics
            all_idkt_p.extend(torch.masked_select(y[:, 1:], sm).cpu().numpy())
            all_bkt_p.extend(torch.masked_select(bkt_p_batch, sm).cpu().numpy())
            
            idkt_im_batch = initmastery[:, 1:]
            idkt_r_batch = rate[:, 1:]

            # Static BKT Priors for Initial Mastery alignment
            bkt_im_static_batch = torch.zeros_like(cshft).float().to(device)
            for b in range(cshft.shape[0]):
                for s in range(cshft.shape[1]):
                    skill_id = cshft[b, s].item()
                    if skill_id != -1:
                        bkt_im_static_batch[b, s] = bkt_skill_params['params'].get(skill_id, bkt_skill_params['global'])['prior']

            all_idkt_initmastery.extend(torch.masked_select(idkt_im_batch, sm).cpu().numpy())
            all_bkt_initmastery.extend(torch.masked_select(bkt_im_static_batch, sm).cpu().numpy())
            
            # Reference rates
            ref_rate_batch = torch.zeros_like(cshft).float().to(device)
            for b in range(cshft.shape[0]):
                for s in range(cshft.shape[1]):
                    skill_id = cshft[b, s].item()
                    if skill_id != -1:
                        ref_rate_batch[b, s] = bkt_skill_params['params'].get(skill_id, bkt_skill_params['global'])['learns']
            
            all_idkt_rate.extend(torch.masked_select(idkt_r_batch, sm).cpu().numpy())
            all_bkt_rate.extend(torch.masked_select(ref_rate_batch, sm).cpu().numpy())

            # Export interaction records for heatmap
            for b in range(uids.shape[0]):
                uid = uids[b].item()
                if uid >= max_export_students: continue
                
                # Get indices where mask is true for this student
                student_mask = sm[b]
                indices = torch.where(student_mask)[0]
                
                for idx in indices:
                    # 1. Parameter Alignment (Static vs Static) - FOR THE GREEN PLOT
                    param_records.append({
                        'student_id': uid,
                        'skill_id': cshft[b, idx].item(),
                        'Mi': idkt_im_batch[b, idx].item(), # static projection
                        'M_rasch': bkt_im_static_batch[b, idx].item(), # static prior
                    })

                    # 2. Trajectory Alignment (Dynamic vs Dynamic) - THE GUIDANCE PLOT
                    traj_records.append({
                        'student_id': uid,
                        'skill_id': cshft[b, idx].item(),
                        'Mi': y[b, idx+1].item(), # iDKT prediction
                        'M_rasch': bkt_p_batch[b, idx+1].item() if idx+1 < bkt_p_batch.shape[1] else bkt_p_batch[b, idx].item(), # BKT prediction
                    })

    # Save Record Files
    if param_records:
        df_param = pd.DataFrame(param_records)
        param_path = os.path.join(args.output_dir, "mastery_test.csv") # Kept as mastery_test.csv for backward compatibility with plot script
        df_param.to_csv(param_path, index=False)
        print(f"✓ Saved Parameter Alignment (Static): {param_path}")
        
        df_traj = pd.DataFrame(traj_records)
        traj_path = os.path.join(args.output_dir, "mastery_trajectory.csv")
        df_traj.to_csv(traj_path, index=False)
        print(f"✓ Saved Trajectory Alignment (Dynamic): {traj_path}")

    # Calculate Alignment Metrics
    results = {}
    
    def calc_metrics(name, pred, ref):
        mse = np.mean((pred - ref)**2)
        corr, _ = pearsonr(pred, ref)
        return {f"{name}_mse": float(mse), f"{name}_corr": float(corr)}

    results.update(calc_metrics("prediction", np.array(all_idkt_p), np.array(all_bkt_p)))
    results.update(calc_metrics("initmastery", np.array(all_idkt_initmastery), np.array(all_bkt_initmastery)))
    results.update(calc_metrics("learning_rate", np.array(all_idkt_rate), np.array(all_bkt_rate)))

    print("\nAlignment Results:")
    for k, v in results.items():
        print(f"  {k}: {v:.4f}")

    os.makedirs(args.output_dir, exist_ok=True)
    with open(os.path.join(args.output_dir, "interpretability_alignment.json"), "w") as f:
        json.dump(results, f, indent=2)

if __name__ == "__main__":
    main()
