nohup: ignoring input
usage: train_gainakt2exp.py [-h] [--config CONFIG] --dataset DATASET --fold
                            FOLD --epochs EPOCHS --batch_size BATCH_SIZE
                            --learning_rate LEARNING_RATE --weight_decay
                            WEIGHT_DECAY --optimizer OPTIMIZER --seed SEED
                            [--use_wandb] [--use_amp] [--auto_shifted_eval]
                            --monitor_freq MONITOR_FREQ --gradient_clip
                            GRADIENT_CLIP --patience PATIENCE
                            [--use_mastery_head] [--disable_mastery_head]
                            [--use_gain_head] [--disable_gain_head]
                            [--intrinsic_gain_attention]
                            [--disable_intrinsic_gain_attention]
                            [--enhanced_constraints] [--pure_bce]
                            --non_negative_loss_weight
                            NON_NEGATIVE_LOSS_WEIGHT
                            --monotonicity_loss_weight
                            MONOTONICITY_LOSS_WEIGHT
                            --mastery_performance_loss_weight
                            MASTERY_PERFORMANCE_LOSS_WEIGHT
                            --gain_performance_loss_weight
                            GAIN_PERFORMANCE_LOSS_WEIGHT
                            --sparsity_loss_weight SPARSITY_LOSS_WEIGHT
                            --consistency_loss_weight CONSISTENCY_LOSS_WEIGHT
                            [--enable_alignment_loss]
                            [--disable_alignment_loss] --alignment_weight
                            ALIGNMENT_WEIGHT --alignment_warmup_epochs
                            ALIGNMENT_WARMUP_EPOCHS [--adaptive_alignment]
                            [--disable_adaptive_alignment]
                            --alignment_min_correlation
                            ALIGNMENT_MIN_CORRELATION --alignment_share_cap
                            ALIGNMENT_SHARE_CAP --alignment_share_decay_factor
                            ALIGNMENT_SHARE_DECAY_FACTOR
                            [--enable_global_alignment_pass]
                            [--disable_global_alignment_pass]
                            --alignment_global_students
                            ALIGNMENT_GLOBAL_STUDENTS
                            [--use_residual_alignment]
                            --alignment_residual_window
                            ALIGNMENT_RESIDUAL_WINDOW
                            [--enable_retention_loss]
                            [--disable_retention_loss] --retention_delta
                            RETENTION_DELTA --retention_weight
                            RETENTION_WEIGHT [--enable_lag_gain_loss]
                            [--disable_lag_gain_loss] --lag_gain_weight
                            LAG_GAIN_WEIGHT --lag_max_lag LAG_MAX_LAG
                            --lag_l1_weight LAG_L1_WEIGHT --lag_l2_weight
                            LAG_L2_WEIGHT --lag_l3_weight LAG_L3_WEIGHT
                            --consistency_rebalance_epoch
                            CONSISTENCY_REBALANCE_EPOCH
                            --consistency_rebalance_threshold
                            CONSISTENCY_REBALANCE_THRESHOLD
                            --consistency_rebalance_new_weight
                            CONSISTENCY_REBALANCE_NEW_WEIGHT --variance_floor
                            VARIANCE_FLOOR --variance_floor_patience
                            VARIANCE_FLOOR_PATIENCE
                            --variance_floor_reduce_factor
                            VARIANCE_FLOOR_REDUCE_FACTOR
                            --warmup_constraint_epochs
                            WARMUP_CONSTRAINT_EPOCHS
                            [--enable_cosine_perf_schedule]
                            --max_semantic_students MAX_SEMANTIC_STUDENTS
                            --seq_len SEQ_LEN --d_model D_MODEL --n_heads
                            N_HEADS --num_encoder_blocks NUM_ENCODER_BLOCKS
                            --d_ff D_FF --dropout DROPOUT --emb_type
                            {qid,concept,hybrid}
train_gainakt2exp.py: error: the following arguments are required: --dataset, --epochs, --weight_decay, --optimizer, --monitor_freq, --gradient_clip, --patience, --non_negative_loss_weight, --monotonicity_loss_weight, --mastery_performance_loss_weight, --gain_performance_loss_weight, --sparsity_loss_weight, --consistency_loss_weight, --alignment_weight, --alignment_warmup_epochs, --alignment_min_correlation, --alignment_share_cap, --alignment_share_decay_factor, --alignment_global_students, --alignment_residual_window, --retention_delta, --retention_weight, --lag_gain_weight, --lag_max_lag, --lag_l1_weight, --lag_l2_weight, --lag_l3_weight, --consistency_rebalance_epoch, --consistency_rebalance_threshold, --consistency_rebalance_new_weight, --variance_floor, --variance_floor_patience, --variance_floor_reduce_factor, --warmup_constraint_epochs, --max_semantic_students, --seq_len, --n_heads
