# GainAKT3Exp Model Status

**Document Version**: 2025-11-19 (Decision to Revert)  
**Model Status**: üî¥ CRITICAL - REVERTING TO LAST KNOWN GOOD COMMIT

---

## üö® CRITICAL DECISION: Code Revert Required

**Decision Date**: November 19, 2025  
**Action**: Revert to commit 2acdc355 (Nov 16, 02:28 UTC)  
**Reason**: Unresolved Encoder 1 AUC drop from 0.7232 ‚Üí 0.6645

### Quick Summary

After 3 days of investigation testing 7+ hypotheses with multiple restoration attempts, the root cause of the AUC drop introduced in commit b59d7e41 remains unidentified. All code comparisons show identical logic, all parameters match, yet performance is degraded by ~6 AUC points. The decision to revert ensures we maintain a stable baseline for continued development.

**See**: `tmp/DIAGNOSTIC_REPORT_AUC_DROP.md` for complete investigation details

### Commits Involved
- **Good**: 2acdc355 - Last working state (Val AUC=0.7232) ‚úÖ
- **Bad**: b59d7e41 - Parameter cleanup that broke performance ‚ùå
- **Current**: Multiple failed restoration attempts (Val AUC=0.665-0.690)

### Next Steps
1. ‚úÖ Document investigation (this file + diagnostic report)
2. ‚úÖ Commit documentation
3. ‚è≥ Create backup branch of current HEAD
4. ‚è≥ Hard reset to 2acdc355
5. ‚è≥ Validate baseline (reproduce experiment 714616)
6. ‚è≥ Resume development with incremental changes

---

## Reference Documents

- Architecture foundations: `gainakt3exp_architecture_approach.md`
- Diagrams and sequences: `gainakt3exp_architecture_diagrams.md`
- Parameter evolution: `examples/reproducibility.md`

---

## Design Foundation: Core Hypotheses

The GainAKT3Exp dual-encoder architecture is built on four foundational hypotheses that define how the model learns and predicts:

### Hypothesis 1: Learning Gains from Interactions
**Premise**: The model can learn the skill-specific learning gains associated with each student-question interaction.

**Implementation**: Encoder 2 processes interaction sequences and projects representations to per-skill gain vectors via `gains_projection: [D] ‚Üí [num_c]`, where each skill gets an independent gain value for each timestep.

### Hypothesis 2: Mastery from Gain Aggregation
**Premise**: The mastery level of each student, for each skill, at each sequence step, can be calculated from the aggregation of learning gains obtained from interactions involving that skill.

**Implementation**: 
```python
# Accumulate gains over time for each skill
effective_practice[t, skill] = sum(skill_gains[0:t, skill])

# Model mastery with sigmoid learning curves
mastery[t, skill] = M_sat[skill] √ó sigmoid(Œ≤[skill] √ó Œ≥[student] √ó effective_practice[t, skill] - offset)
```

The q-matrix relates questions to skills, ensuring gains accumulate correctly per skill.

### Hypothesis 3: Response Prediction from Mastery States
**Premise**: We can predict whether a response is correct from the mastery states of all skills related to the question.

**Educational Rule Applied**: Answering a question correctly requires mastery of ALL related skills. If all relevant skills have mastery above a threshold Œ∏, the response is predicted as correct. If one or more skills are below threshold, the response is predicted as incorrect.

**Implementation**:
```python
# Mastery-based prediction (hard rule)
encoder2_pred = sigmoid((mastery[t, relevant_skills].min() - Œ∏) / temperature)

# Alternative (soft rule): Average mastery across skills
# encoder2_pred = sigmoid((mastery[t, relevant_skills].mean() - Œ∏) / temperature)
```

### Hypothesis 4: IM Loss for Mastery-Based Learning
**Premise**: The Incremental Mastery (IM) loss function compares predictions calculated from mastery states (Hypothesis 3) with true responses, providing supervision signal for the entire interpretability path.

**Implementation**:
```python
# IM loss trains: gains ‚Üí effective_practice ‚Üí mastery ‚Üí response_prediction
im_loss = BCE(encoder2_pred, true_responses)

# Gradients flow back through:
# im_loss ‚Üí encoder2_pred ‚Üí mastery ‚Üí effective_practice ‚Üí skill_gains ‚Üí gains_projection ‚Üí Encoder2
```

**Key Insight**: This creates a differentiable interpretability path where Encoder 2 learns to:
1. Extract meaningful gain representations from interactions
2. Model skill-specific mastery progression
3. Predict responses based on cognitive mastery states

**Expected Behavior**: 
- **Encoder 2 SHOULD predict responses** (via mastery-based rule) and achieve reasonable AUC (~0.60-0.65)
- **Encoder 2 AUC improving** indicates the interpretability path is learning correctly
- **Encoder 2 AUC staying random (~0.50)** indicates the mastery ‚Üí response prediction path is broken

---

## Version Summary

| Version | Description | Key Innovation | Conclusion |
|---------|-------------|----------------|------------|
| **Phase 0** | Baseline dual-encoder | Sigmoid learning curves + dual loss (BCE+IM) | ‚ùå Scalar gains - cannot learn skill-specific patterns (Enc2 AUC=0.484) |
| **V1** | Per-skill gains | `gains_projection: [D]‚Üí[num_c]` enables skill-specific gradients | ‚ö†Ô∏è Fixed architecture but gains uniform (std=0.0015, all ~0.585) |
| **V2** | Gain interpretation | Per-skill, per-timestep gain logging from logits | ‚ö†Ô∏è Marginal improvement (std=0.0017), still 99.8% uniform |
| **V3** | Explicit differentiation | Variance loss + skill-contrastive loss + beta spread regularization | ‚ùå FAILED - gains collapsed to uniform (std=0.0018, no improvement) |
| **V3+** | Asymmetric initialization | Bias ~ N(0, 0.5) + orthogonal weights + V3 losses | ‚ùå FAILED - worse than V3 (std=0.0016), initial asymmetry lost by epoch 2 |
| **V3++** | BCE weight tuning | Tested 0.1, 0.3, 0.5 with full V3+ mechanisms | ‚ùå FAILED - all converged to std~0.0017, <0.01% difference across weights |
| **V4** | Semantic grounding | External difficulty scaling (post-projection) | ‚ùå FAILED - compensatory learning, network canceled semantic scaling (CV 94% loss) |
| **V5** | Architectural constraint | Difficulty as INPUT feature (pre-projection) | ‚ùå FAILED - identical to V4 (CV=0.0122), network learned to ignore input |
| **Clean Baseline** | Diagnostic configuration | V3+ features disabled, bce_weight=0.9 | ‚úÖ Val AUC=0.723 (Nov 16) - best performance, establishes target |
| **IM Fix** | AUC drop investigation | Reverted IM loss to current responses | üî¥ CRITICAL FAILURE - AUC=0.665 (Nov 19), worse than ever, Enc2 learning |

**Key Finding**: Uniform gains (~0.585) is optimization inevitability - BCE+IM loss landscape creates global attractor regardless of initialization, loss weights, explicit penalties, or external supervision. All 10 differentiation experiments failed.

**Current Priority**: Restore AUC baseline (0.665‚Üí0.723) before resuming differentiation work. Root cause unknown - requires deep architectural comparison.

---

## Current Status

**Critical Issue**: AUC Drop from 0.724 to 0.665 (Nov 16-19, 2025)  
**Investigation Status**: Root cause NOT yet identified - IM loss target reversion failed  
**Clean Baseline Status**: Dual-encoder architecture with V3+ features disabled (required for fair comparison)

**AUC Drop Investigation** (Nov 19, 2025):

**Good Experiment** (714616, Nov 16, commit 2acdc35):
- Val AUC: **0.7232** ‚úÖ
- BCE Loss: 0.511
- IM Loss: 0.631
- Encoder2 AUC: 0.490 (random baseline)
- Configuration: Clean dual-encoder, bce_loss_weight=0.9

**Failed Restoration Attempt** (869310, Nov 19):
- Val AUC: **0.6645** ‚ùå (WORSE than recent experiments!)
- BCE Loss: 0.553
- IM Loss: 0.605
- Encoder2 AUC: 0.592 (learning)
- Configuration: Attempted IM loss target reversion (responses instead of responses_shifted)

**Key Differences from Good Experiment**:
- ‚ùå IM loss target reversion did NOT restore AUC
- ‚ùå Encoder2 still learning (not random like good experiment)
- ‚ùå Overall performance degraded vs recent baselines (~0.69)
- ‚ö†Ô∏è Something else fundamentally different in architecture or forward pass

**V3+ Features Currently Disabled** (for clean baseline comparison):
- variance_loss_weight: 2.0 ‚Üí 0.0
- skill_contrastive_loss_weight: 1.0 ‚Üí 0.0
- beta_spread_regularization_weight: 0.5 ‚Üí 0.0
- gains_projection_bias_std: 0.5 ‚Üí 0.0
- gains_projection_orthogonal: true ‚Üí false
- **Rationale**: Isolate architectural differences from optimization enhancements

**V3+ Asymmetric Initialization Results** (Experiment 173298):
- ‚ùå Implementation: gains_projection.bias ~ N(0, 0.5)
- ‚úÖ Initial asymmetry: CV=0.24 at epoch 0 (target achieved)
- ‚ùå Training collapse: CV=0.0015 by epoch 2 (worse than V3!)
- ‚ùå Final gain std: 0.0016 (vs V3: 0.0018) - 11% worse
- **Conclusion**: Asymmetry doesn't persist - gradients drive to uniform regardless of initialization

**V3++ BCE Weight Tuning with V3+ Mechanisms** (Experiments 870831, 389068):
- Tested BCE weights: 0.1 (90% IM), 0.3 (70% IM), 0.5 (50% IM baseline)
- All with full V3+ mechanisms (asymmetric init + explicit differentiation)
- **Results**: ALL FAILED
  - BCE=0.1: gain_std=0.001657 (3.3% of target)
  - BCE=0.3: gain_std=0.001680 (3.4% of target)
  - BCE=0.5: gain_std=0.001624 (3.2% of target)
- **Range across 10%-50% BCE**: Only 0.000056 variation (3.5% difference)
- **Conclusion**: BCE weight has MINIMAL effect even with V3+ mechanisms
- All converge to ~0.585 mean, ~0.0017 std (99.8% uniformity)

**V4 Semantic Grounding Results** (Experiment 884821):
- ‚úÖ Implementation: External skill difficulty + student velocity
- ‚úÖ Skill difficulty computation: 3-correct-in-a-row metric (range 0.69-1.90)
- ‚úÖ Expected CV from difficulty: 0.195 (20% variation)
- ‚ùå Actual CV: 0.0122 (only 6.2% of expected)
- ‚ùå Correlation with 1/difficulty: 0.57 (expected ~1.0)
- **Root Cause**: Compensatory learning - network learned gains_projection weights that output `base √ó difficulty[s]`, then scaling by `1/difficulty[s]` canceled to uniform
- **Mathematical proof**: Network can learn `w[s] = log(constant √ó d[s])` so that `sigmoid(w[s]) √ó (1/d[s]) = constant`

**V5 Difficulty as Input Results** (Experiment 510011):
- ‚úÖ Implementation: Difficulty concatenated as INPUT FEATURE before projection
- ‚úÖ Theory: Architectural constraint - cannot "learn away" input features
- ‚ùå Actual CV: 0.0122 (identical to V4!)
- ‚ùå Correlation: 0.57 (identical to V4!)
- **Conclusion**: Network learned to IGNORE difficulty input and produce uniform outputs
- **Fundamental problem**: BCE+IM loss landscape so strongly prefers uniform that even architectural constraints cannot overcome it

**Critical Finding - Optimization Inevitability vs Code Bug**:

‚ö†Ô∏è **IMPORTANT CAVEAT**: The optimization inevitability conclusion (below) was reached while performance was degraded (AUC ~0.665). The current AUC drop investigation suggests we may have introduced a bug that:
1. Broke the architecture's ability to learn effectively (Val AUC: 0.723 ‚Üí 0.665)
2. Caused Encoder2 to learn when it should stay random (Enc2 AUC: 0.490 ‚Üí 0.592)
3. Potentially invalidated all V3-V5 differentiation experiments

**Until AUC baseline is restored to ~0.72**, all conclusions about optimization inevitability remain **tentative**. The bug may have:
- Prevented proper gradient flow in differentiation mechanisms
- Created spurious loss landscape attractors
- Masked the true effectiveness of V3+ features

**Original Optimization Inevitability Hypothesis** (requires validation after bug fix):
- Uniform solution (~0.585) may be GLOBAL OPTIMUM in loss landscape
- May satisfy both BCE and IM losses optimally
- Network may find this solution through ANY architectural path
- Observed across 10 experiments with every approach:
  - Initial asymmetry (V3+) ‚úó
  - Loss balance tuning (V0-V3++) ‚úó
  - Explicit differentiation (V3) ‚úó
  - External semantic anchors (V4) ‚úó
  - Architectural constraints (V5) ‚úó
- **Status**: Requires re-evaluation once clean baseline architecture is confirmed working

**Critical Priority - AUC Drop Investigation** (Nov 19, 2025):

üî¥ **INVESTIGATION COMPLETE - ROOT CAUSE NOT FOUND - REVERTING**

### Investigation Summary (3 Days, 7+ Hypotheses)

**Baseline Performance** (Experiment 714616, Commit 2acdc355):
- Validation AUC: 0.7232 ‚úÖ
- Encoder 2 AUC: 0.490 (random, as expected)
- Date: Nov 16, 02:28 UTC

**Breaking Change** (Commit b59d7e41):
- Date: Nov 16, 15:06 UTC
- Changes: Deprecated 27 parameters, major training script cleanup
- Impact: 43 files, +9258/-2123 lines

**Failed State** (All Experiments After b59d7e41):
- Validation AUC: 0.665-0.690 ‚ùå
- Encoder 2 AUC: 0.59 (learning, unexpected)
- Performance Drop: ~6 AUC points

### Failed Restoration Attempts

| # | Hypothesis | Action Taken | Result | Conclusion |
|---|-----------|--------------|--------|------------|
| 1 | IM loss target | Reverted to `responses` | AUC=0.665 ‚ùå | Not the cause |
| 2 | Double sigmoid | Code review | No issue ‚úÖ | Not the cause |
| 3 | num_students param | Validation logic | Correct ‚úÖ | Not the cause |
| 4 | assist2009 config | Config check | Correct ‚úÖ | Not the cause |
| 5 | use_gain_head | Signature check | Deprecated ‚úÖ | Not the cause |
| 6 | V3+ features | Disabled all | No improvement ‚ùå | Not primary |
| 7 | Code comparison | Line-by-line | Identical logic ‚úÖ | Unknown |

**All investigated parameters match baseline exactly**. Code logic appears identical. Yet performance remains degraded.

### Decision: Revert to Commit 2acdc355

**Rationale**:
1. Exhaustive investigation (7 hypotheses, 3+ days) found no root cause
2. Multiple restoration experiments all failed
3. Continuing on degraded baseline increases technical debt
4. Clean slate from known-good state is lower risk

**Revert Plan**:
1. ‚úÖ Document investigation (DIAGNOSTIC_REPORT_AUC_DROP.md)
2. ‚úÖ Update STATUS (this file)
3. ‚è≥ Commit documentation
4. ‚è≥ Create backup branch (`broken-cleanup-nov19`)
5. ‚è≥ Hard reset to 2acdc355
6. ‚è≥ Validate baseline (reproduce 714616)
7. ‚è≥ Resume with incremental changes

**Lessons Learned**:
- Never deprecate 27 parameters simultaneously
- Always validate after each significant change
- Incremental changes with continuous testing required
- Documentation at commit time, not retrospectively

**See**: `tmp/DIAGNOSTIC_REPORT_AUC_DROP.md` for complete 4000-word investigation report

**Note on V3-V5 Work**: Differentiation experiments (uniform gains problem) remain on hold until baseline restored. May need to be re-evaluated after revert to determine if optimization inevitability conclusions were affected by the performance bug.

---

**Previous Work - Differentiation Strategy** (V3-V5, Nov 18-19):
All approaches exhausted (10 experiments). Options:
1. Hard constraints (clamp gains to fixed ranges) - 20% confidence, compromises learning
2. Accept limitation and document thoroughly - 100% confidence, valid research contribution

See `/workspaces/pykt-toolkit/tmp/INITIALIZATION_THEORY_ANALYSIS.md` for complete theoretical analysis and `examples/experiments/20251118_211102_gainakt3exp_V3-phase1-full-validation_970206/ANALYSIS.md` for detailed failure analysis.

## Architecture Overview

**Dual-Encoder Design**:
- **Encoder 1 (Performance Path)**: 96,513 parameters
  - Components: embeddings (context, value, skill, position), encoder blocks, prediction head
  - Purpose: Learns attention patterns for direct response prediction (unconstrained optimization)
  - Output: Base predictions ‚Üí BCE Loss (weight: 70%)
  
- **Encoder 2 (Interpretability Path)**: 71,040 parameters  
  - Components: embeddings (context, value, position), encoder blocks, gains projection
  - Purpose: Learns skill-specific learning gains through attention patterns
  - Output: Per-skill gains ‚Üí Effective practice ‚Üí Mastery ‚Üí IM Loss (weight: 30%)

- **Sigmoid Learning Curve Parameters**: 22 parameters
  - Œ≤_skill[num_c]: Skill difficulty (learning rate amplification)
  - Œ≥_student[num_students]: Student learning velocity
  - M_sat[num_c]: Maximum mastery saturation per skill
  - Œ∏_global: Global mastery threshold for competence
  - offset: Sigmoid inflection point

**Key Innovation - Differentiable Effective Practice with Per-Skill Gains**:
```python
# Encoder 2 outputs value representations
value_seq_2 = encoder_blocks_2(...)  # [B, L, D]

# Project to per-skill gains (V1+ implementation)
self.gains_projection = nn.Linear(d_model, num_c)  # [D] ‚Üí [num_c]
skill_gains_logits = self.gains_projection(value_seq_2)  # [B, L, num_c]
skill_gains = sigmoid(skill_gains_logits)  # [B, L, num_c] ‚àà [0, 1]

# Per-skill quality-weighted practice accumulation (differentiable!)
effective_practice[:, t, :] += skill_gains[:, t, :]  # Each skill gets different gain!

# Sigmoid learning curves (per-skill mastery)
mastery = M_sat √ó sigmoid(Œ≤_skill √ó Œ≥_student √ó effective_practice - offset)

# Incremental mastery predictions through threshold
encoder2_pred = sigmoid((mastery - Œ∏_global) / temperature)
```

**Gradient Flow**:
- Encoder 1: BCE_loss ‚Üí predictions ‚Üí prediction_head ‚Üí encoder_blocks_1 ‚úÖ
- Encoder 2: IM_loss ‚Üí encoder2_pred ‚Üí mastery ‚Üí effective_practice ‚Üí skill_gains[num_c] ‚Üí gains_projection ‚Üí value_seq_2 ‚Üí encoder_blocks_2 ‚úÖ
  - **Key**: Per-skill gains vector [B, L, num_c] allows skill-specific gradient updates

## Current Implementation (V2 - Per-Skill Gains)

**Code Status**: ‚úÖ Production ready
- File: `pykt/models/gainakt3_exp.py` (909 lines)
- Training: `examples/train_gainakt3exp.py`
- Evaluation: `examples/eval_gainakt3exp.py`

**Active Features**:
- ‚úÖ Dual-encoder architecture with complete independence
- ‚úÖ Per-skill gains projection [B, L, num_c]
- ‚úÖ Differentiable effective practice accumulation
- ‚úÖ Sigmoid learning curves with learnable parameters
- ‚úÖ Dual loss functions (BCE + Incremental Mastery)
- ‚úÖ Comprehensive metrics tracking (30 columns in metrics CSV)

**Inactive/Commented Out**:
- ‚ùå All constraint losses (monotonicity, sparsity, etc.) - weights = 0.0
- ‚ùå All semantic losses (alignment, retention, etc.) - enable flags = false
- ‚ùå Intrinsic gain attention mode - deprecated
- ‚ùå Explicit gains head output - use_gain_head = false

## Performance Summary

### V2 Results (820618 - Latest Complete Run)

| Metric | Train | Validation | Test | Target | Status |
|--------|-------|------------|------|--------|--------|
| **Overall AUC** | 0.7152 | 0.6893 | - | >0.70 | ‚úÖ |
| **Encoder 1 AUC** | 0.7152 | 0.6893 | 0.6825 | >0.68 | ‚úÖ |
| **Encoder 2 AUC** | 0.5977 | 0.5969 | 0.5931 | >0.55 | ‚úÖ Above random |
| **Mastery Correlation** | 0.0362 | - | 0.0379 | >0.30 | ‚ùå Too low |
| **Gain Std** | - | - | 0.0017 | >0.05 | ‚ùå Nearly uniform |

**Key Observations**:
- ‚úÖ Encoder 1 performs well (68-69% AUC)
- ‚ö†Ô∏è Encoder 2 above random baseline but struggles with skill differentiation
- ‚ùå Gains converge to near-uniform values (std=0.0017)
- ‚ùå Mastery poorly correlated with actual performance

**Root Cause**: Mixed training signals (50% BCE + 50% IM from epoch 1) allow model to find compromise solution with uniform gains (~0.585) that satisfies both objectives without learning skill-specific patterns.

## Active Parameters (37 total)

Defaults defined in `configs/parameter_default.json`:

**Model Architecture (7)**:
- seq_len=200, d_model=256, n_heads=4, num_encoder_blocks=4, d_ff=256, dropout=0.1, emb_type="qid"

**Learning Curve (5)**:
- beta_skill_init=2.5, m_sat_init=0.7, gamma_student_init=1.1, sigmoid_offset=1.5, mastery_threshold_init=0.85

**Training (8)**:
- learning_rate=0.000174, batch_size=64, epochs=20, patience=10, optimizer="adam", weight_decay=0.0001, gradient_clip=1.0, bce_loss_weight=0.5

**Interpretability (4)**:
- use_mastery_head=true, use_gain_head=false, threshold_temperature=1.0, variance_loss_weight=0.1

**Data (2)**: dataset="assist2015", fold=0
**Monitoring (2)**: monitor_freq=50, use_wandb=true
**Misc (9)**: seed, use_amp, auto_shifted_eval, max_correlation_students, num_students, use_skill_difficulty, use_student_speed, train_script, eval_script

## Known Issues

### Critical Issue: Uniform Gains Problem - FUNDAMENTAL LIMITATION

**Symptom**: Encoder 2 learns near-uniform gain values across all skills (std~0.0017)

**Impact**:
- Cannot differentiate skill-specific learning rates
- Mastery trajectories not predictive of performance (correlation~0.04)
- Encoder 2 AUC only marginally above random (~59%)

**Root Cause**: Loss landscape drives toward uniform solution (global attractor)
- Uniform gains (~0.585 all skills) satisfy both BCE and IM losses
- Encoder 1 dominance provides strong BCE signal
- Encoder 2 finds uniform solution optimal at ANY loss weight
- Even explicit anti-uniformity losses insufficient to escape attractor

**Attempted Fixes**:
1. **V2**: Loss weight tuning (30%‚Üí50% IM), variance loss, layer-wise LR, extended training ‚Üí marginal (+0.0002 std)
2. **V3**: Explicit differentiation (contrastive loss, beta spread, variance√ó20) ‚Üí no improvement
3. **V3+**: Asymmetric initialization (bias_std=0.5, CV=0.24 at epoch 0) ‚Üí collapsed to uniform (CV=0.0015)
4. **BCE Weight Analysis**: Tested 0%-100% ‚Üí only 0.0004 variation (21% of tiny baseline)

**Proven Independence**:
- ‚ùå Loss weight: 0%-100% BCE produces identical uniform gains
- ‚ùå Initialization: Asymmetric (CV=0.24) collapses during training
- ‚ùå Explicit losses: Contrastive, variance√ó20, beta spread all fail
- **Conclusion**: Problem is architectural/optimization, not tunable parameters

---

# Next Steps

## FINAL DECISION: Accept Limitation and Document

**Status**: All approaches exhausted after 10 experiments

**Experiments Completed**:
1. V0: Baseline (scalar gains) - Broken
2. V1: Per-skill gains - Uniform (std=0.0015)
3. V2: Loss tuning + variance loss - Uniform (std=0.0017)
4. V3: Explicit differentiation - Uniform (std=0.0018)
5. V3+: Asymmetric initialization - Uniform (std=0.0016)
6. V3++ BCE=0.1: V3+ with 90% IM - Uniform (std=0.0017)
7. V3++ BCE=0.3: V3+ with 70% IM - Uniform (std=0.0017)
8. V2 BCE sweep: Baseline at 0%, 50%, 100% - All uniform
9. V4: Semantic grounding (external supervision) - Uniform (std=0.0061, compensatory learning)
10. V5: Difficulty as input (architectural constraint) - Uniform (std=0.0061, learned to ignore)

**Proven Facts**:
- ‚úó Loss weight tuning (0%-100% BCE): Negligible effect
- ‚úó Explicit differentiation (contrastive, variance√ó20, beta spread): Failed
- ‚úó Asymmetric initialization (CV=0.24‚Üí0.002): Collapses during training
- ‚úó Combined V3+ with BCE tuning: No interaction effect
- ‚úó External semantic supervision (V4): Network compensates to cancel
- ‚úó Architectural constraints (V5): Network learns to ignore input
- ‚úÖ Uniform gains (~0.585) is global optimum in loss landscape - mathematically inevitable

### Option A: Semantic Grounding via External Supervision (Confidence: 70%) - ‚ùå TESTED AND FAILED

**Objective**: Break uniform attractor by introducing **external semantic anchors** from observable learning patterns, not just optimization signals.

**Core Principles** (based on learning science):

1. **Skill Difficulty (Population-level Memory)**:
   - Observable: Skills requiring more practice across students are harder
   - Compute: `avg_practice_needed[skill] / global_avg_practice`
   - Application: Harder skills ‚Üí lower base gains (need more repetitions)
   - This is **data-driven**, not learned from loss alone

2. **Student Learning Velocity (Student-level Memory)**:
   - Observable: Some students learn faster across all skills
   - Compute: `student_mastery_rate / avg_mastery_rate`
   - Application: Faster learners ‚Üí gains multiplied by velocity factor
   - This is **student-specific**, constant across their sequence

**Why This Could Work**:
- ‚úÖ External supervision breaks uniform attractor (not purely loss-driven)
- ‚úÖ Forced differentiation: Skills naturally have different difficulty
- ‚úÖ Semantic meaning: Aligns with learning science (harder skills need more practice)
- ‚úÖ Student personalization: Velocity factor per student
- ‚úÖ Observable from data: Not arbitrary, grounded in actual patterns

**Mathematical Formulation**:
```python
# Pre-computed from training data (before model training)
skill_difficulty[s] = avg_practice_needed[s] / global_avg_practice
# Range: 0.5 (easy) to 2.0 (hard)

# Computed per student from their history
student_velocity[i] = student_mastery_rate[i] / avg_mastery_rate
# Range: 0.5 (slow) to 2.0 (fast)

# Semantically-grounded gains
semantic_gain[i,t,s] = base_gain[t,s] / skill_difficulty[s] * student_velocity[i]
```

**Implementation Plan** (~5 hours total):

**Phase 1: Data Preprocessing** (2 hours):
```python
# 1. Compute skill difficulty from training data
def compute_skill_difficulty(dataset):
    skill_practice_counts = defaultdict(list)
    for student in dataset:
        practices_to_mastery = {}
        for interaction in student:
            skill_id = interaction['skill']
            if skill_id not in practices_to_mastery:
                practices_to_mastery[skill_id] = 0
            practices_to_mastery[skill_id] += 1
            if interaction['response'] == 1:  # Mastery achieved
                skill_practice_counts[skill_id].append(practices_to_mastery[skill_id])
                practices_to_mastery[skill_id] = 0  # Reset
    
    global_avg = np.mean([np.mean(v) for v in skill_practice_counts.values()])
    skill_difficulty = {
        skill_id: np.mean(counts) / global_avg 
        for skill_id, counts in skill_practice_counts.items()
    }
    return skill_difficulty

# 2. Save to data directory
save_json(skill_difficulty, 'data/assist2015/skill_difficulty.json')
```

**Phase 2: Model Modification** (2 hours):
```python
# In pykt/models/gainakt3_exp.py
class GainAKT3Exp(nn.Module):
    def __init__(self, ..., skill_difficulty_path=None):
        # Load pre-computed skill difficulty (fixed, not learned)
        if skill_difficulty_path:
            difficulty_dict = load_json(skill_difficulty_path)
            self.skill_difficulty = torch.tensor(
                [difficulty_dict.get(i, 1.0) for i in range(num_c)]
            )
        else:
            self.skill_difficulty = torch.ones(num_c)
    
    def forward(self, q, r, ..., student_velocities=None):
        # Base gains from Encoder 2
        skill_gains_base = torch.sigmoid(
            self.gains_projection(value_seq_2)
        )  # [B, L, num_c]
        
        # Apply skill difficulty scaling (harder ‚Üí lower gains)
        difficulty_scaling = 1.0 / self.skill_difficulty.to(q.device)
        difficulty_scaling = difficulty_scaling.unsqueeze(0).unsqueeze(0)
        skill_gains = skill_gains_base * difficulty_scaling
        
        # Apply student velocity scaling (if provided)
        if student_velocities is not None:
            velocity_scaling = student_velocities.unsqueeze(1).unsqueeze(2)
            skill_gains = skill_gains * velocity_scaling
        
        # Continue with effective practice accumulation...
```

**Phase 3: Training Updates** (1 hour):
```python
# In examples/train_gainakt3exp.py

# Track student history for velocity computation
student_history_tracker = defaultdict(lambda: {'correct': 0, 'total': 0})

for epoch in range(epochs):
    for batch in train_loader:
        # Compute student velocities for this batch
        student_velocities = []
        for student_id in batch['student_ids']:
            history = student_history_tracker[student_id.item()]
            if history['total'] > 0:
                velocity = (history['correct'] / history['total']) / global_avg_rate
            else:
                velocity = 1.0  # Neutral for new students
            student_velocities.append(velocity)
        
        student_velocities = torch.tensor(student_velocities).to(device)
        
        # Forward pass with semantic grounding
        outputs = model(q, r, ..., student_velocities=student_velocities)
        
        # Update student history
        for student_id, responses in zip(batch['student_ids'], batch['responses']):
            student_history_tracker[student_id.item()]['total'] += len(responses)
            student_history_tracker[student_id.item()]['correct'] += responses.sum().item()
```

**Phase 4: Quick Test** (30 minutes):
```bash
python examples/run_repro_experiment.py \
    --short_title V4-semantic-grounding \
    --epochs 5 \
    --skill_difficulty_path data/assist2015/skill_difficulty.json \
    --use_student_velocity \
    --gains_projection_bias_std 0.5 \
    --skill_contrastive_loss_weight 1.0 \
    --beta_spread_regularization_weight 0.5 \
    --variance_loss_weight 2.0
```

**Success Criteria**:
- Gain std >0.05 (semantic anchors force differentiation)
- Gains negatively correlated with skill difficulty (harder ‚Üí lower)
- Student velocity visible in gain patterns (faster learners ‚Üí higher gains)
- Maintains Encoder1 AUC >0.66
- Encoder2 AUC >0.60

**Results** (Experiments 884821, 510011):
- **V4 (post-processing)**: CV=0.0122, Correlation=0.57 - Network compensated by learning inverse pattern
- **V5 (input feature)**: CV=0.0122, Correlation=0.57 - Network learned to ignore difficulty input
- **Conclusion**: FAILED - Loss landscape too strong, defeats both semantic supervision and architectural constraints

### Option B: Hard Constraints (Confidence: 20%) - NOT RECOMMENDED

**Objective**: Force differentiation through architectural constraints

**Implementation** (~2 hours):
1. Add minimum inter-skill distance constraint to forward pass
2. During training, project gains to satisfy: `min(|gain_i - gain_j|) > threshold`
3. Gradual threshold relaxation: 0.15 ‚Üí 0.10 ‚Üí 0.05 over epochs
4. Makes differentiation **architecturally required**, not optimization-encouraged

**Rationale**: 
- Only approach that FORCES differentiation regardless of gradients
- Changes feasible solution space, not just loss landscape

**Risks**:
- **Updated after V5**: If architectural input constraints failed (V5), hard constraints unlikely to work
- May severely hurt performance (constrained optimization against loss landscape)
- Implementation complexity
- V4/V5 evidence suggests loss landscape will defeat any constraint mechanism
- 20% confidence (reduced from 40% after V5 failure)

**Recommendation**: Skip this option, proceed directly to Option C

### Option C: Accept Limitation and Reframe (Confidence: 100%) - FALLBACK

**Rationale**: After 8 experiments and all parameter tuning exhausted, uniform gains is proven to be an inherent optimization characteristic, not a solvable bug.

**Actions** (1 week):

1. **Document Limitation** (`paper/ARCHITECTURAL_LIMITATIONS.md`):
   - Complete experimental history (8 experiments)
   - Mathematical analysis of why uniform is optimal
   - Theoretical implications for dual-objective optimization
   - Honest scientific documentation

2. **Reframe Paper Contributions**:
   - **Remove**: "Skill-specific learning rates" as primary contribution
   - **Keep**: Dual-encoder architecture design and rationale
   - **Keep**: Differentiable sigmoid learning curves
   - **Keep**: Attention pattern interpretability
   - **Keep**: Mastery trajectory modeling
   - **Add**: Limitations section (uniform gains phenomenon)
   - **Add**: Lessons learned about dual-objective optimization

3. **Emphasize Successful Aspects**:
   - Dual-encoder design for performance vs interpretability tradeoff
   - Encoder 1: Strong performance (68-69% AUC)
   - Encoder 2: Above random, learns reasonable mastery curves
   - Architectural innovation even if skill differentiation failed
   - Valuable negative result for research community

4. **Update Documentation**:
   - README: Honest description of capabilities
   - STATUS: Complete experimental record
   - Code comments: Document uniform gains characteristic

**Why This Is Valid Research**:
- Rigorously tested hypothesis (8 experiments)
- Honest documentation of what doesn't work
- Valuable for community (prevents others from repeating)
- Still contributes dual-encoder architecture insights
- Demonstrates thorough scientific method

### Recommended Path Forward

**Decision Made**: Proceed with Option C (Accept Limitation)

**Evidence** (10 experiments, all failed):
1-3. Loss weight tuning (V0-V2): Uniform gains regardless of BCE/IM balance
4-5. Explicit differentiation (V3, V3+): Contrastive loss + initialization failed
6-8. Combined approaches (V3++, sweeps): No interaction effects
9. External supervision (V4): Network compensated to cancel semantic signal
10. Architectural constraint (V5): Network learned to ignore difficulty input

**Why Option C**:
- ‚úÖ 10 experiments is overwhelming evidence
- ‚úÖ Tried every approach: parameters, initialization, losses, external supervision, architecture
- ‚úÖ V4/V5 proved even architectural constraints cannot overcome loss landscape
- ‚úÖ Hard constraints (Option B) unlikely to work after V5 failure (20% confidence)
- ‚úÖ Further attempts unlikely to succeed without fundamental architecture redesign
- ‚úÖ Valid research contribution: Document what doesn't work and why
- ‚úÖ Honest scientific documentation more valuable than continued failures

**Next Actions**:
1. Document V4/V5 findings thoroughly (compensatory learning + architectural failure)
2. Update paper to reframe contributions (dual-encoder design, not skill differentiation)
3. Write limitations section explaining optimization inevitability
4. Commit all changes and prepare final documentation

## V3 Enhanced Strategy Overview (DEPRECATED)

**Rationale**: Loss weight analysis across 6 experiments (BCE=0%-100%) revealed uniform gains problem is **independent of loss balance** (std varies only 0.0002 across all weights). V2's approach (tuning weights) cannot work. V3 targets root cause with explicit anti-uniformity mechanisms.

**V3 Strategy**: Explicit Skill Differentiation (NOT inverse warmup)
- **Phase 1** (Implemented, awaiting validation):
  - Skill-contrastive loss (weight=1.0): Cross-skill comparison forces differentiation
  - Variance loss increase (0.1‚Üí2.0): 20x stronger anti-uniformity signal  
  - Beta spread initialization: N(2.0, 0.5) starts with clear variation
  - Beta spread regularization (weight=0.5): Prevents collapse during training
  
- **Phase 2** (If Phase 1 insufficient):
  - Gain-response correlation loss (weight=0.5): Semantic supervision
  - Curriculum amplification: 2x weights in early epochs
  - Dropout in gains_projection (0.2): Prevent co-adaptation

**Expected Improvements** (once bug fixed):
| Metric | V2 | V3 Target | Required Improvement |
|--------|----|-----------|--------------------|
| Gain std | 0.0017 | >0.05 | 30x |
| Beta spread | N/A | >0.3 maintained | New metric |
| Encoder2 AUC | 59.7% | >62% | +2.3% |
| Mastery correlation | 0.11 | >0.40 | 4x |

**Success Criteria**:
- ‚úÖ Per-skill gains show variance (std >0.05)
- ‚úÖ Different skills have different learning rates (CV >0.2)
- ‚úÖ Mastery correlates with responses (>0.40)
- ‚úÖ Encoder2 AUC above random and improving (>62%)
- ‚úÖ Beta spread preserved throughout training (std >0.3)
- ‚úÖ Response-conditional gains (ratio >1.2)

See `V3_IMPLEMENTATION_STRATEGY.md` for complete implementation details, mathematical formulations, and monitoring strategy.

## Alternative Approaches (If V3 Fails)

**Option 1: Multi-layer Gains Projection**
- Replace single linear layer with MLP (d_model ‚Üí d_model ‚Üí num_c)
- Adds non-linear capacity for complex skill relationships
- Try if: gain std between 0.02-0.05 after V3

**Option 2: Initialization Strategy**  
- Smaller weight initialization (std=0.01 vs default)
- Prevents strong uniform bias at initialization
- Try if: gain std between 0.05-0.10 after V3

**Option 3: Skill-Aware Attention**
- Add skill similarity bias to attention scores
- Help model focus on skill-specific patterns
- Try if: gain std <0.02 after V3 (last resort)

## Tasks

**Immediate** (within 24 hours):
- [ ] Implement inverse warmup schedule in train_gainakt3exp.py
- [ ] Update parameter_default.json: epochs=30, bce_loss_weight schedule
- [ ] Launch V3 training with monitoring
- [ ] Track skill_gains std during training (should increase in Phase 1)

**Short-term** (within 1 week):
- [ ] Extract and analyze V3 trajectories
- [ ] Run 6 verification checks on V3 results
- [ ] Compare V1 vs V2 vs V3 across all metrics
- [ ] Document findings and update STATUS
- [ ] If successful: commit changes and proceed to multi-seed validation
- [ ] If unsuccessful: implement Option 2 and retry

**Medium-term** (within 1 month):
- [ ] Multi-seed validation (3 seeds) once V3 succeeds
- [ ] Cross-dataset validation (ASSIST2009, etc.)
- [ ] Ablation studies on schedule parameters
- [ ] Write paper section on inverse warmup strategy

---

# Historic Evolution

## Timeline Overview

| Date | Version | Key Changes | Val AUC | Encoder2 AUC | Gain Std | Status |
|------|---------|-------------|---------|--------------|----------|--------|
| 2025-11-16 | Baseline | Dual-encoder architecture, sigmoid curves | N/A | 0.4842 | N/A | ‚ùå Broken (scalar gains) |
| 2025-11-16 | Clean | Dual-encoder, bce=0.9, V3+ disabled | **0.7232** | 0.490 | N/A | ‚úÖ GOOD (commit 2acdc35) |
| 2025-11-17 | V1 | Per-skill gains fix | N/A | 0.5868 | 0.0015 | ‚ö†Ô∏è Above random, uniform gains |
| 2025-11-17 | V2 | Multiple interventions | N/A | 0.5969 | 0.0017 | ‚ö†Ô∏è Marginal improvement |
| 2025-11-18 | V3 Bug Fix | Fixed indentation bug (311 lines) | N/A | 0.5891 | N/A | ‚úÖ Mastery head active |
| 2025-11-18 | V3 Phase 1 | Explicit differentiation | N/A | 0.5935 | 0.0018 | ‚ùå FAILED |
| 2025-11-18 | V3+ | Asymmetric initialization BCE=0.5 | N/A | N/A | 0.0016 | ‚ùå FAILED (worse!) |
| 2025-11-18 | V3++ BCE=0.1 | V3+ with 90% IM weight | N/A | N/A | 0.0017 | ‚ùå FAILED |
| 2025-11-18 | V3++ BCE=0.3 | V3+ with 70% IM weight | N/A | N/A | 0.0017 | ‚ùå FAILED |
| 2025-11-19 | V4 | Semantic grounding (post-processing) | N/A | N/A | 0.0061 | ‚ùå FAILED (compensatory learning) |
| 2025-11-19 | V5 | Difficulty as input (architectural) | N/A | N/A | 0.0061 | ‚ùå FAILED (identical to V4) |
| 2025-11-19 | IM Fix | Revert IM loss to current responses | **0.6645** | 0.592 | N/A | üî¥ CRITICAL (worse than ever!) |

## Bug 0: Skill Index Mismatch (2025-11-17) - FIXED

**Discovery**: encoder2_pred used mastery for NEXT skill (qry[t] = q[t+1]) instead of CURRENT skill (q[t])

**Impact**:
- 22.2% prediction mismatches (214/966 predictions)
- 98.2% of mismatches at skill transitions
- Misaligned training supervision
- Invalid interpretability claims

**Fix**: Changed `skill_indices = target_concepts.long()` to `skill_indices = q.long()` in line 622 of gainakt3_exp.py

**Validation**: 100% match rate after fix (0% mismatches) ‚úÖ

## Phase 0: Baseline Architecture (999787) - BROKEN

**Experiment**: 20251117_131554_gainakt3exp_baseline-bce0.7_999787

**Architecture Bug**: Scalar gain quality instead of per-skill gains

```python
# WRONG: Single scalar per interaction
gain_quality = sigmoid(value_seq_2.mean(dim=-1))  # [B, L, 1]
effective_practice[t, practiced_skill] += gain_quality[t]  # Same for ALL skills
```

**The Problem**:
- ‚úÖ Model can learn: "This interaction had high/low engagement"
- ‚ùå Model cannot learn: "Student improved Skill A by 0.8, Skill B by 0.2"
- Result: All practiced skills get identical increment

**Performance**:
- Encoder 1 AUC: 0.6765 ‚úÖ (working well)
- **Encoder 2 AUC: 0.4842** ‚ùå (below random baseline!)
- Mastery ‚Üî Response correlation: -0.044 (essentially zero)
- Encoder2_pred range: [0.37, 0.53] (too narrow, indecisive)

**Trajectory Analysis** (659 interactions):
- Mastery IS updating (sigmoid progression visible)
- BUT mastery uncorrelated with actual performance
- Mastery increases even after incorrect responses
- Predictions compressed near 0.5 (cannot discriminate)

**Root Cause**: Scalar gain quality learns overall engagement, not skill-specific learning. No amount of parameter tuning can fix this architectural limitation.

## Phase 1: Per-Skill Gains Fix - V1 (995130)

**Experiment**: 20251117_154349_gainakt3exp_fixed-per-skill-gains_995130

**Architecture Fix**: Implemented per-skill gains vector

```python
# CORRECT: Per-skill gains projection
self.gains_projection = nn.Linear(d_model, num_c)  # [D] ‚Üí [num_c]
skill_gains = sigmoid(self.gains_projection(value_seq_2))  # [B, L, num_c]
effective_practice[:, t, :] += skill_gains[:, t, :]  # Skill-specific!
```

**Configuration**:
- bce_loss_weight: 0.7 (30% IM loss)
- epochs: 12
- learning_rate: 0.000174
- patience: 10

**Performance**:
- Encoder 1 AUC: 0.6897 ‚úÖ
- **Encoder 2 AUC: 0.5868** ‚úÖ (above random, +10.3% from baseline)
- Mastery correlation: 0.037 (improved from -0.044, but still too low)

**Critical Finding**: Gains are nearly uniform across all skills!
```
Gain statistics:
  Mean: 0.5884
  Std: 0.0015 ‚Üê Nearly constant!
  Range: 0.01 (0.583 to 0.593)
```

**Trajectory Verification** (6 checks):
- ‚úÖ CHECK 1: Skill differentiation - **FAILED** (CV=0.0016, target >0.2)
- ‚úÖ CHECK 2: Q-Matrix learning - PASS (1.0 skills/interaction)
- ‚úÖ CHECK 3: Monotonicity - PASS (0 violations)
- ‚ùå CHECK 4: Mastery correlation - FAIL (0.033, target >0.3)
- ‚ùå CHECK 5: Skill difficulty - FAIL (CV=0.0016)
- ‚ùå CHECK 6: Response-conditional - FAIL (ratio=1.00, target >1.2)

**Success Rate**: 2/6 checks (33%)

**Conclusion**: Architectural fix successful (Encoder2 above random), but optimization fails to learn skill-specific patterns. Gains converge to uniform solution.

## Phase 2: Multiple Interventions - V2 (820618)

**Experiment**: 20251117_162330_gainakt3exp_fixed-per-skill-gains-v2_820618

**Objective**: Address V1's uniform gains problem with 4 targeted interventions

**Changes**:
1. **Priority 1 - Increased IM Loss**: 30% ‚Üí 50% (stronger gradient signal to Encoder 2)
2. **Priority 2 - Added Variance Loss**: weight=0.1 (explicitly penalize uniform gains)
3. **Priority 3 - Extended Training**: 12 ‚Üí 20 epochs (early stopped at 15)
4. **Priority 4 - Layer-wise LR**: gains_projection LR 3x boost (0.000522 vs 0.000174)

**Configuration**:
- bce_loss_weight: 0.5 (50% IM loss)
- variance_loss_weight: 0.1
- epochs: 20 (early stopped: 15)
- gains_projection_lr: 0.000522 (3x base)
- patience: 10

**Performance vs V1**:
| Metric | V1 | V2 | Change | Improvement |
|--------|----|----|--------|-------------|
| Encoder1 Val AUC | 0.6897 | 0.6893 | -0.04% | Stable |
| **Encoder2 Val AUC** | 0.5868 | **0.5969** | **+1.0%** | ‚ö†Ô∏è Marginal |
| Encoder2 Test AUC | 0.5835 | 0.5931 | +1.0% | ‚ö†Ô∏è Marginal |
| Gain Std | 0.0015 | **0.0017** | +0.0002 | ‚ùå Negligible |
| Mastery Correlation | 0.037 | **0.113** | **+0.076 (3x)** | ‚ö†Ô∏è Better but still low |

**Trajectory Verification** (6 checks):
- ‚úÖ CHECK 3: Monotonicity - PASS
- ‚úÖ CHECK 2: Q-Matrix learning - PASS  
- ‚úÖ CHECK 4: Mastery correlation - **IMPROVED** (0.113 vs target >0.3)
- ‚ùå CHECK 1: Skill differentiation - FAIL (CV=0.0019, target >0.2)
- ‚ùå CHECK 5: Skill difficulty - FAIL
- ‚ùå CHECK 6: Response-conditional - FAIL

**Success Rate**: 3/6 checks (50%) - slight improvement from V1's 33%

**Training Dynamics**:
```
Epoch  Enc1_Val  Enc2_Val  Notes
  1    0.679     0.585     Pattern established early
  5    0.704     0.598     Best epoch (peak)
  15   0.715     0.589     Final (early stopped)
```

**Key Finding**: Despite ALL interventions, gains remain 99.8% uniform!
```
Gain statistics:
  Mean: 0.5854
  Std: 0.0017 ‚Üê Still nearly constant!
  Range: 0.0105
```

**Why V2 Failed**: 
- Mixed signals (50% BCE + 50% IM from epoch 1) still allow compromise
- Model finds uniform gains (~0.585) that satisfy both objectives
- Gets stuck in local minimum early (epoch 5-6)
- More epochs don't help - pattern established from initialization

**Critical Discovery - Loss Weight Analysis** (comparing 3 experiments):

Analyzed gain uniformity across different BCE/IM balances:
- **Exp 999787** (BCE=70%, IM=30%): gain_std=0.0015, CV=0.0016
- **Exp 995130** (BCE=70%, IM=30%): gain_std=0.0015, CV=0.0016  
- **Exp 820618** (BCE=50%, IM=50%): gain_std=0.0017, CV=0.0019

**Key Insight**: Uniform gains problem **independent of loss balance**!
- 30% vs 50% IM weight: Only 0.0002 std difference (negligible)
- All experiments converge to ~0.585 mean with <0.002 std
- Pattern established by epoch 1-5, persists through training

**Implication**: Simply adjusting loss weights (V2 approach) cannot solve uniform gains. The model finds uniform solution immediately and never escapes, regardless of balance.

**Conclusion**: Need **fundamentally different training strategy** that prevents uniform solution from forming. V3 changes approach from temporal scheduling (inverse warmup) to explicit anti-uniformity mechanisms (cross-skill comparison, spread preservation).

## Critical Bug Fix: Orphaned Indentation (2025-11-18) - FIXED

**Discovery**: During V3 Phase 1 validation, discovered IM loss=0.0 despite all V3 code implemented and qry=None set in 5 locations.

**Root Cause**: Line 458 in gainakt3_exp.py had commented-out conditional:
```python
# elif self.use_gain_head and self.use_mastery_head:
```

However, lines 459-769 (311 lines) remained indented at 12 spaces (should be 8 spaces), indicating they were still part of the commented elif's body. This created orphaned code that never executed because controlling conditional was commented out.

**Bug Impact**:
- Lines 459-769: 311-line mastery computation block never executed
- Line 770: Orphaned `else:` always executed instead, setting all mastery variables to None
- Result: Mastery head completely disabled since parameter simplification (~2025-11-16)
- ALL experiments from V0 through V3 affected (none had working mastery head)

**Fix Method**:
1. Created `/workspaces/pykt-toolkit/tmp/fix_indentation_bug.py`
2. Un-indented lines 459-769 from 12 spaces to 8 spaces (4-space shift)
3. Removed orphaned else block (lines 770-777)
4. Backup created: `gainakt3_exp.py.backup_before_unindent`
5. Verified with Python compilation test

**Validation** (Experiment 269777):
```bash
python examples/run_repro_experiment.py \
    --short_title V3-FIXED-indentation-bug \
    --epochs 2 --num_workers 32
```

**Results** - Mastery head now ACTIVE! ‚úÖ
| Metric | Epoch 1 | Epoch 2 | Status |
|--------|---------|---------|--------|
| IM Loss | 0.6079 | 0.6060 | ‚úÖ Non-zero! (was 0.0) |
| Encoder2 Val AUC | 0.5833 | 0.5891 | ‚úÖ Above random |
| Mastery Correlation (train) | - | 0.036 | ‚úÖ Positive |
| Mastery Correlation (test) | - | 0.038 | ‚úÖ Positive |
| Beta Spread (std) | 0.496 | 0.496 | ‚úÖ Maintained >0.3 |

**Learned Parameters** (confirming all V3 components functional):
- beta_skill: std=0.496 (spread preserved throughout training)
- gamma_student: std=0.238 (student differentiation)
- theta_global: 0.850‚Üí0.786 (learning threshold decreasing as expected)

**Key Insight**: Bug existed since parameter simplification but went undetected because:
1. Python interpreter didn't flag indentation as syntax error (valid as unreachable code)
2. Tests only checked IM loss computation code existence, not runtime execution
3. Gradual parameter removal left orphaned indented blocks without triggering warnings

**Lesson Learned**: When commenting out conditionals during refactoring, must verify downstream indentation adjusted for remaining code blocks. AST analysis insufficient - indentation-level analysis required.

## Phase 3: V3 Enhanced Strategy - Explicit Differentiation (970206) - FAILED

**Experiment**: 20251118_211102_gainakt3exp_V3-phase1-full-validation_970206

**Objective**: Address V2's uniform gains with explicit anti-uniformity mechanisms (skill-contrastive loss, beta spread init/regularization, variance√ó20)

**Strategic Shift**: After analyzing loss weight independence (gain_std varies only 0.0002 across BCE 0%-100%), implemented explicit differentiation instead of loss scheduling.

**Result**: Complete failure - gains remained 99.8% uniform despite all V3 components active for 14 epochs.

**V3 Phase 1 Implementation** (2025-11-18):

### 1. Skill-Contrastive Loss (NEW)
**Purpose**: Explicitly force cross-skill comparison (addresses IM Loss independence)

**Mathematical Formulation**:
```python
# For each interaction, compute variance across all skill gains
gain_variance_per_interaction = skill_gains.var(dim=2)  # [B, L]
skill_contrastive_loss = -gain_variance_per_interaction.mean()  # Maximize variance
```

**Implementation**: Line 557-562 in gainakt3_exp.py, new method `compute_skill_contrastive_loss()` at lines 875-922

**Parameters**: `skill_contrastive_loss_weight = 1.0`

### 2. Beta Spread Initialization (MODIFIED)
**Purpose**: Start training with differentiated skill difficulties

**Change**:
```python
# OLD: Uniform initialization
self.beta_skill = torch.nn.Parameter(torch.ones(num_c) * beta_skill_init)

# NEW: Spread initialization N(2.0, 0.5) clamped [0.5, 5.0]
beta_init_values = torch.randn(num_c) * 0.5 + beta_skill_init
beta_init_values = torch.clamp(beta_init_values, 0.5, 5.0)
self.beta_skill = torch.nn.Parameter(beta_init_values)
```

**Implementation**: Line 306-310 in gainakt3_exp.py

**Rationale**: Prevents symmetric starting point that favors uniform solution

### 3. Beta Spread Regularization (NEW)
**Purpose**: Prevent beta_skill collapse during training

**Mathematical Formulation**:
```python
beta_std = self.beta_skill.std()
beta_spread_loss = max(0, 0.3 - beta_std) ** 2  # Hinge loss
```

**Implementation**: Line 564-567 in gainakt3_exp.py, new method `compute_beta_spread_regularization()` at lines 924-954

**Parameters**: `beta_spread_regularization_weight = 0.5`

### 4. Variance Loss Amplification (MODIFIED)
**Change**: `variance_loss_weight: 0.1 ‚Üí 2.0` (20x increase)

**Rationale**: Original weight too weak to overcome uniform attractor

**Configuration Updates**:
- `configs/parameter_default.json`: Added 3 new parameters
- `examples/parameters_audit.py`: Updated to require 15 parameters (was 12)
- `examples/train_gainakt3exp.py`: Loss computation includes all V3 terms
- All 9 reproducibility audit checks passing ‚úÖ

### V3 Phase 1 Complete Results - FAILED (970206)

**Experiment**: 20251118_211102_gainakt3exp_V3-phase1-full-validation_970206 (20 epochs requested, early stopped at 14)

**Configuration**: All V3 Phase 1 components active
- skill_contrastive_loss_weight=1.0
- beta_spread_regularization_weight=0.5
- variance_loss_weight=2.0 (20x amplification)
- Beta spread init: N(2.0, 0.5) clamped [0.5, 5.0]

**Performance Results**:
| Metric | Result | Target | Gap |
|--------|--------|--------|-----|
| Best Val AUC (Enc1) | 0.6648 (epoch 4) | >0.68 | -2.3% |
| Encoder2 Val AUC | 0.5935 | >0.62 | -4.3% |
| Gain std | 0.0018 | >0.10 | 55x short |
| Gain CV | 0.002 | >0.20 | 100x short |
| Mastery correlation | 0.039 | >0.40 | 10x short |
| Response ratio | 1.00 | >1.2 | No differentiation |
| Beta spread std | 0.448 | >0.3 | ‚úÖ ONLY success |

**Comparison to V2 Baseline** (820618):
- Encoder1 Val AUC: 0.6648 vs 0.6893 (-3.55%) ‚ùå WORSE
- Encoder2 Val AUC: 0.5935 vs 0.5969 (-0.58%) ‚ùå WORSE
- Mastery correlation: 0.039 vs 0.113 (-65.6%) ‚ùå MUCH WORSE
- Gain std: 0.0018 vs 0.0017 (+0.0001) ‚âà NO CHANGE

**Gain Statistics** (66 skills observed, 14 epochs):
```
Mean: 0.588341
Std: 0.001820 (target >0.10)
Min: 0.582953, Max: 0.593400
Range: 0.010447 (1.7% variation)
CV: 0.003094 (99.7% uniformity)
Per-skill CV: 0.002061 (target >0.20)
```

**Training Dynamics**:
- Peak performance: Epoch 4 (Val AUC 0.6648)
- Early stopping: Epoch 14 (patience=10 triggered)
- Pattern: Uniform gains established by epoch 1, never escaped
- Beta spread: Maintained throughout training (0.496‚Üí0.448)

**Root Cause Discovery**: Symmetric initialization problem
- PyTorch default `nn.Linear(256, 100)` produces per-skill CV=0.017 at initialization
- All 100 skills nearly identical outputs (~0.50 after sigmoid)
- Creates uniform attractor that V3 losses cannot escape
- Beta spread init didn't help (downstream parameter, doesn't affect gains_projection layer)

**Why V3 Failed**:
1. Started from symmetric initialization (CV=0.017)
2. Forward pass produces uniform gains (~0.50 all skills)
3. Backward pass has nearly identical gradients for all skills
4. SGD update preserves uniformity (symmetry principle)
5. V3 losses (contrastive, variance) too weak vs Encoder1 dominance
6. Uniform local minimum established epoch 1, never escapes

**V3 Success Criteria**: 1/6 passed (only beta spread maintained >0.3)

**Conclusion**: V3 Phase 1 did NOT solve uniform gains problem. Despite all explicit differentiation mechanisms active (skill-contrastive loss, beta spread init/regularization, variance√ó20), the fundamental issue is **symmetric initialization** creating a uniform attractor. V3 losses cannot break symmetry when starting from nearly identical skill parameters. Performance degraded vs V2, suggesting V3 components add noise without solving core problem.

**Detailed Analysis**: See `examples/experiments/20251118_211102_gainakt3exp_V3-phase1-full-validation_970206/ANALYSIS.md`

## Phase 4: V3+ Asymmetric Initialization (173298) - FAILED

**Experiment**: 20251118_[timestamp]_gainakt3exp_V3-plus-asymmetric-init-test_173298 (2 epochs)

**Objective**: Test if asymmetric bias initialization can break uniform attractor

**Hypothesis**: Symmetric PyTorch initialization (CV=0.017) creates uniform starting point. Asymmetric initialization should create differentiation that persists during training.

**Implementation**:
```python
# Added to pykt/models/gainakt3_exp.py (lines 278-325)
if gains_projection_bias_std > 0:
    skill_bias = torch.randn(num_c) * gains_projection_bias_std  # N(0, 0.5)
    self.gains_projection.bias.data = skill_bias
    if gains_projection_orthogonal:
        nn.init.orthogonal_(self.gains_projection.weight)
```

**Parameters**:
- gains_projection_bias_std: 0.5
- gains_projection_orthogonal: true
- All V3 losses active (contrastive=1.0, variance=2.0, beta_spread=0.5)

**Results - COMPLETE FAILURE**:
| Metric | Epoch 0 | Epoch 2 | Target | Status |
|--------|---------|---------|--------|--------|
| Initial asymmetry (CV) | 0.240 | - | >0.20 | ‚úÖ Target achieved |
| **Training collapse** | - | 0.0015 | Maintain >0.20 | ‚ùå COLLAPSED |
| Gain std | - | 0.0016 | >0.10 | ‚ùå 62x short |
| Gain mean | - | 0.5929 | - | Uniform attractor |

**Comparison to V3 Phase 1**:
- V3 gain std: 0.0018 (14 epochs)
- V3+ gain std: 0.0016 (2 epochs)
- **Change: -11% (WORSE!)**
- V3 per-skill CV: 0.0021
- V3+ per-skill CV: 0.0015
- **Change: -29% (WORSE!)**

**Critical Finding - Asymmetry Doesn't Persist**:
1. Initialization successfully created asymmetry (CV=0.24 at epoch 0) ‚úÖ
2. BUT: Training immediately collapsed back to uniformity (CV=0.0015 by epoch 2) ‚ùå
3. Initial advantage lost within 2 epochs
4. Even worse uniformity than V3 by end of training

**Why V3+ Failed**:
- Initialization breaks symmetry temporarily but cannot maintain it
- Problem: Gradient flow during training, not initialization
- Uniform solution (~0.585) is global attractor in loss landscape
- V3 losses too weak vs Encoder 1 dominance
- SGD updates drive toward uniform regardless of starting point

**Theoretical Prediction**: 70-90% confidence ‚Üí **0% actual success**
- Symmetry breaking theory (Goodfellow) insufficient
- Lottery Ticket Hypothesis doesn't apply (not pruning scenario)
- Misidentified problem: Loss landscape, not initialization

**Lesson Learned**: Initialization can break symmetry but cannot prevent gradient-driven collapse to uniform attractor.

## Phase 5: V3++ BCE Weight Tuning with V3+ Mechanisms (870831, 389068) - FAILED

**Objective**: Test if lower BCE weight (more IM signal) helps preserve V3+ initial asymmetry

**Hypothesis**: V3+ creates asymmetry (CV=0.24) but it collapses with BCE=0.5. Maybe lower BCE weight would help maintain differentiation during training.

**Experiments Tested** (5 epochs each):
| Exp ID | BCE Weight | IM Weight | Config | Gain Std | Per-skill CV | Status |
|--------|-----------|-----------|--------|----------|--------------|--------|
| 870831 | 0.1 | 0.9 | V3++ | 0.001657 | 0.001854 | ‚ùå FAILED |
| 389068 | 0.3 | 0.7 | V3++ | 0.001680 | 0.001844 | ‚ùå FAILED |
| 173298 | 0.5 | 0.5 | V3+ baseline | 0.001624 | 0.001524 | ‚ùå FAILED |

All with full V3+ mechanisms:
- gains_projection_bias_std=0.5 (asymmetric initialization)
- gains_projection_orthogonal=true
- skill_contrastive_loss_weight=1.0
- beta_spread_regularization_weight=0.5
- variance_loss_weight=2.0

**Results - ALL FAILED**:
- **Target**: Gain std >0.05 (50x improvement)
- **Actual**: Gain std ~0.0017 (97% short of target, 3.3% achievement)
- **BCE weight effect**: Range of only 0.000056 across 10%-50% BCE
- **Variation**: 3.5% difference - essentially NEGLIGIBLE

**Key Findings**:
1. **Initial asymmetry present**: V3+ creates CV=0.24 at epoch 0 ‚úÖ
2. **Asymmetry collapses**: By epoch 2, CV drops to ~0.002 ‚ùå
3. **BCE weight irrelevant**: 10% vs 50% BCE makes <4% difference
4. **All converge to uniform**: ~0.585 mean, ~0.0017 std (99.8% uniformity)

**Why BCE Weight Tuning Failed (Even with V3+ Mechanisms)**:

1. **Uniform Solution Is Optimal**:
   - Uniform gains (~0.585) minimize combined BCE + IM loss
   - Any differentiation increases loss for both objectives
   - SGD correctly finds this global minimum

2. **Encoder 1 Dominance**:
   - Provides strong, stable gradients (BCE loss)
   - Encoder 2 adapts to minimize interference
   - Uniform gains = minimal impact on Encoder 1

3. **IM Loss Satisfaction**:
   - Uniform gains produce reasonable mastery curves
   - Model learns: "all skills contribute equally" works
   - No pressure to differentiate when uniform satisfies IM

4. **Loss Weight Cannot Override Optimization**:
   - Even 90% IM weight (BCE=0.1) insufficient
   - Gradients drive toward uniform regardless of balance
   - Loss landscape structure dominates tuning

**Comparison to Previous Hypotheses**:
| Approach | Tested | Result | Reason for Failure |
|----------|--------|--------|-------------------|
| V2: Loss weight tuning | ‚úì | FAILED | Insufficient alone |
| V3: Explicit differentiation | ‚úì | FAILED | Losses too weak vs uniform optimum |
| V3+: Asymmetric init | ‚úì | FAILED | Collapses during training |
| V3++: V3+ + BCE tuning | ‚úì | FAILED | No interaction effect, uniform optimal |

**Critical Insight - Uniform Gains Is Optimization Inevitability**:
- Not a bug, not a parameter tuning issue
- Mathematical consequence of dual-objective optimization
- Uniform solution is GLOBAL OPTIMUM in this loss landscape
- Cannot be solved by parameter tuning alone

**Conclusion**: All parameter tuning approaches exhausted (8 experiments total). Uniform gains cannot be solved through:
- Loss weight adjustments ‚úó
- Explicit differentiation losses ‚úó
- Asymmetric initialization ‚úó
- Any combination of the above ‚úó

## Detailed Implementation History

### Sigmoid Learning Curve Implementation (2025-11-16) - COMPLETE

**Changes**:
- Added 5 learnable parameters for sigmoid curves: Œ≤_skill, Œ≥_student, M_sat, Œ∏_global, offset
- Replaced linear accumulation with practice count-driven sigmoid: `mastery = M_sat √ó sigmoid(Œ≤ √ó Œ≥ √ó practice_count - offset)`
- Updated threshold prediction mechanism (global Œ∏ instead of per-skill)
- Created comprehensive test suite (tmp/test_sigmoid_curves.py) - all tests passed ‚úÖ

**Educational Semantics**:
- Œ≤_skill: Skill difficulty (learning rate amplification)
- Œ≥_student: Student learning velocity (personalization)
- M_sat: Maximum achievable mastery per skill
- Œ∏_global: Competence threshold (decision boundary)
- offset: Inflection point (when rapid learning begins)

**Test Results**: Clear sigmoid pattern verified (mastery: 0.095 ‚Üí 0.400 ‚Üí 0.705 ‚Üí 0.786 ‚Üí 0.800 over 20 practices)

### Dual-Encoder Architecture Implementation (2025-11-16) - COMPLETE

**Changes**:
- Changed class definition: `class GainAKT3Exp(GainAKT3)` ‚Üí `class GainAKT3Exp(nn.Module)` (standalone)
- Implemented two completely independent encoder stacks (no shared parameters)
- Encoder 1: 96,513 parameters (embeddings, blocks, prediction head)
- Encoder 2: 71,040 parameters (embeddings, blocks, no prediction head)
- Differentiable effective practice: quality-weighted accumulation for gradient flow

**Critical Innovation - Per-Skill Gains with Differentiable Accumulation**:
```python
# V1+ architecture: Per-skill gains projection (not scalar!)
self.gains_projection = nn.Linear(d_model, num_c)  # Project to skills
skill_gains = sigmoid(self.gains_projection(value_seq_2))  # [B, L, num_c]

# Per-skill differentiable accumulation
effective_practice[:, t, :] += skill_gains[:, t, :]  # Skill-specific rates!
```

**Gradient Flow**: IM_loss ‚Üí mastery[num_c] ‚Üí effective_practice[num_c] ‚Üí skill_gains[num_c] ‚Üí gains_projection ‚Üí value_seq_2 ‚Üí Encoder 2 parameters

**Test Suite** (tmp/test_dual_encoders.py):
- Test 1-4: Architecture verification ‚úÖ
- **Test 5: Gradient flow** ‚úÖ (CRITICAL - both encoders receive gradients)
- Test 6-7: Independent learning ‚úÖ

**Result**: ALL 7 TESTS PASSED. Model ready for training.

### Dual-Encoder Metrics and Monitoring (2025-11-16) - COMPLETE

**Enhanced CSV Metrics** (30 columns total):
- Overall metrics: train/val loss, AUC, accuracy
- Loss components: BCE, IM (unweighted raw losses)
- Weighted losses: BCE√óŒª‚ÇÅ, IM√óŒª‚ÇÇ, total
- Loss shares: BCE%, IM%
- Encoder-specific: Encoder1 AUC/acc, Encoder2 AUC/acc
- Interpretability quality: monotonicity violations, negative gains, mastery/gain correlations

**Monitoring Hook**: Updated to pass both encoder states (context_seq_1, value_seq_1, context_seq_2, value_seq_2) for dual-encoder comparison analysis

**Learning Trajectories**: Enhanced to show:
- Multi-skill support (per-skill gains and mastery)
- Dual predictions (Encoder1 vs Encoder2)
- Per-skill learning gains for relevant skills
- Effective practice accumulation

### Parameter Simplification (2025-11-16) - COMPLETE

**Objective**: Remove 27 deprecated parameters from CLI, reduce from 70 to 37 active parameters

**Deprecated Categories**:
- 6 constraint loss weights (all 0.0)
- 9 semantic alignment parameters (all inactive)
- 2 global alignment parameters (enable=false)
- 6 semantic refinement parameters (all inactive)
- 3 warmup/scheduling parameters (not used)
- 1 architecture parameter (intrinsic_gain_attention)

**Result**: CLI commands require ~15 essential parameters instead of 64, cleaner interface aligned with dual-encoder architecture

### Learning Curve Parameter Calibration (2025-11-16) - COMPLETE

**Phase 1 Sweep**: Optimize sigmoid parameters (beta, m_sat, gamma, offset)
- Grid: 81 experiments (3√ó3√ó3√ó3)
- Dataset: assist2015, fold 0
- Fixed: bce_loss_weight=0.2 (80% signal to Encoder2)
- Hardware: 7 GPUs parallel, ~6 hours, 100% success

**Results**:
- Best: E2 AUC = 0.5443 (Beta=2.5, M_sat=0.7, Gamma=1.1, Offset=1.5) ‚Üí +6.7% vs baseline
- Parameter impact: beta (+0.72 strong), offset (-0.54 moderate), gamma (+0.41 weak), m_sat (-0.10 minimal)

**Key Pattern - "Steep Early Learning"**:
- High beta (2.5): Sharp transitions between "not mastered" and "mastered"
- Low offset (1.5): Measurable mastery after 1-2 practice attempts
- High gamma (1.1): Personalized learning pace for faster learners
- Conservative m_sat (0.7): Prevents overconfidence

**Updated Defaults** (effective 2025-11-16):
- beta_skill_init: 2.0 ‚Üí 2.5 (+0.5)
- m_sat_init: 0.8 ‚Üí 0.7 (-0.1)
- gamma_student_init: 1.0 ‚Üí 1.1 (+0.1)
- sigmoid_offset: 2.0 ‚Üí 1.5 (-0.5)

**Documentation**: Complete reports in `paper/PHASE1_SWEEP_REPORT.md` and `paper/PHASE1_SWEEP_SUMMARY.md`

**Phase 2** (Pending): Balance loss weights using optimal learning curve parameters from Phase 1

---

# Appendix: Technical Details

## Loss Functions

**Active Losses**:
1. **BCE Loss**: Binary cross-entropy on base predictions from Encoder 1
   - Applied to: prediction_head_1 output
   - Weight: 70% (default in V2 phase 2)
   - Purpose: Optimize response prediction accuracy

2. **Incremental Mastery Loss**: Binary cross-entropy on mastery-based predictions from Encoder 2
   - Applied to: `sigmoid((mastery - Œ∏) / temperature)` output
   - Weight: 30% (default in V2 phase 2)
   - Purpose: Train mastery values to be predictive of responses

**Commented Out** (preserved in code for reference):
- Constraint losses: non_negative, monotonicity, mastery_performance, gain_performance, sparsity, consistency (all weight=0.0)
- Semantic losses: alignment, global_alignment, retention, lag_gain (all enable=false, weight=0.0)

## Architecture Compliance

| Feature | Specification | Implementation | Status |
|---------|---------------|----------------|--------|
| Dual Encoders | Two independent stacks | 167,575 params (96,513 + 71,040 + 22) | ‚úÖ Active |
| Differentiable Practice | Quality-weighted accumulation | gain_quality ‚Üí effective_practice | ‚úÖ Active |
| Sigmoid Learning Curves | Practice-driven mastery | 5 learnable parameters | ‚úÖ Active |
| Per-Skill Gains | Skill-specific learning rates | gains_projection layer | ‚úÖ Active |
| Dual Predictions | Base + mastery-based | BCE + IM losses | ‚úÖ Active |
| Constraint Losses | 6 educational constraints | All commented out | ‚ùå Inactive |
| Semantic Alignment | Population-level coherence | All commented out | ‚ùå Inactive |

## Experiment Directories

- **V0 (Baseline - Broken)**: `examples/experiments/20251117_131554_gainakt3exp_baseline-bce0.7_999787`
- **V1 (Per-Skill Gains)**: `examples/experiments/20251117_154349_gainakt3exp_fixed-per-skill-gains_995130`
- **V2 (Multiple Interventions)**: `examples/experiments/20251117_162330_gainakt3exp_fixed-per-skill-gains-v2_820618`
- **V3 (Inverse Warmup)**: TBD

## Trajectory Analysis Tools

**Extract Trajectories**:
```bash
python examples/learning_trajectories.py \
  --run_dir examples/experiments/{exp_dir} \
  --num_students 10 \
  --min_steps 10
```

**Verification Checks** (6 total):
1. Skill differentiation: gain std >0.05, CV >0.2
2. Q-Matrix learning: avg skills/interaction ‚âà 1.0
3. Monotonicity: violation rate = 0.0
4. Mastery correlation: correlation >0.3
5. Skill difficulty: CV >0.2
6. Response-conditional: correct/incorrect gain ratio >1.2

## Parameter Evolution Protocol

All parameter changes documented in `examples/reproducibility.md` following protocol:
1. Update `configs/parameter_default.json` (source of truth)
2. Document rationale in commit message
3. Run `python examples/parameters_fix.py` to update MD5 hash
4. Update `paper/parameters.csv` with change justification

---

**Document Version**: 2025-11-19  
**Last Updated**: After AUC drop investigation and num_students parameter analysis

---

## Appendix A: num_students Parameter Investigation (Nov 19, 2025)

### Issue Summary

During AUC drop investigation (baseline 0.724 ‚Üí current 0.665), discovered potential issue with `num_students` parameter management and its relationship to dataset statistics.

### Background

**Parameter Usage**:
- `num_students` allocates `gamma_student` tensor for per-student learning velocity: `torch.nn.Parameter(torch.ones(num_students) * gamma_student_init)`
- When `use_student_speed=True` and `student_ids` provided: `gamma = self.gamma_student[student_ids]` (indexing operation)
- When `use_student_speed=False`: Uses `gamma.mean()` fallback, no student_id indexing

**Dataset Metadata (assist2015 fold 0)**:
- Training data: 12220 unique students (student_ids: 0-12219)
- Validation data: 3055 unique students (student_ids: 0-3054)
- Dataset metadata: Reports 12220 (all folds combined)
- Parameter default: 3055

### Investigation Findings

**1. Baseline Configuration (Experiment 714616, commit 2acdc35)**:
- num_students: 3055
- use_student_speed: False
- Val AUC: 0.7232 ‚úÖ
- Encoder2 AUC: 0.490 (random)
- **Why it worked**: use_student_speed=False means no indexing, uses gamma.mean() fallback

**2. Index Safety Analysis**:
```python
# IF use_student_speed=True AND student_ids provided:
gamma = self.gamma_student[student_ids]  # Requires num_students >= max(student_ids) + 1

# IF use_student_speed=False:
gamma = self.gamma_student.mean()  # Safe with any num_students value
```

**3. Validation Logic Added** (lines 130-158 in train_gainakt3exp.py):
```python
# Extract num_students from dataset dynamically
num_students_from_data = train_loader.dataset.dori['num_students']
logger.info(f"Dataset contains {num_students_from_data} students (max student_id + 1)")

# Validate compatibility
if num_students != num_students_from_data:
    if use_student_speed:
        # CRITICAL ERROR: Would cause index out of bounds
        raise ValueError(f"num_students={num_students} insufficient for {num_students_from_data} students")
    else:
        # SAFE: gamma_student not indexed by student_id
        logger.warning(f"Using parameter value: {num_students} (SAFE: use_student_speed=False)")
```

### Resolution

**Current Implementation**:
- ‚úÖ Dynamic extraction of num_students from dataset metadata
- ‚úÖ Clear logging of parameter vs dataset mismatch
- ‚úÖ Safety validation: Throws error if use_student_speed=True with insufficient num_students
- ‚úÖ Warning when safe mismatch (use_student_speed=False)
- ‚úÖ Adheres to zero-defaults policy (no fallback values, fails if metadata missing)

**Why num_students=3055 Works for Baseline**:
1. Baseline has use_student_speed=False (parameter not used for indexing)
2. Code uses gamma.mean() fallback when student_ids not provided
3. No individual gamma_student elements accessed, so 3055-element tensor sufficient
4. Even though dataset has 12220 students, the tensor is never indexed by student_id

**Parameter Value Decision**:
- Keep num_students=3055 matching baseline for reproducibility
- Safe because current experiments also use use_student_speed=False
- If enabling use_student_speed in future, must set num_students=12220

### Status

- ‚úÖ Validation logic implemented and tested
- ‚úÖ Comprehensive logging for debugging
- ‚úÖ Safety checks prevent index errors
- ‚è∏Ô∏è **NOT the root cause of AUC drop** - Failed restoration attempt (869310) with proper num_students still produced AUC=0.665
- ‚è∏Ô∏è Issue documented for future reference if enabling use_student_speed

### Related Code

- Model: `pykt/models/gainakt3_exp.py` lines 438-450 (gamma_student allocation), lines 760-780 (usage)
- Training: `examples/train_gainakt3exp.py` lines 130-158 (validation logic)
- Parameter defaults: `configs/parameter_default.json`

### Recommendations

1. **For current work**: No changes needed, validation logic prevents future issues
2. **If enabling use_student_speed**: Set num_students to dataset's actual value (12220 for assist2015)
3. **For other datasets**: Validation logic will automatically detect and warn/error appropriately
4. **Documentation**: This appendix serves as reference for parameter management decisions
