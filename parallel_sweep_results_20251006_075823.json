[
  {
    "run_id": 1,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0013773711515336754,
      "weight_decay": 6.16028523360776e-05,
      "num_encoder_blocks": 6,
      "d_ff": 640,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.2773365357865857,
      "mastery_performance_loss_weight": 2.4403762003058382,
      "gain_performance_loss_weight": 2.165088420770237,
      "monotonicity_loss_weight": 0.2570839999734971,
      "sparsity_loss_weight": 0.16734096262232723,
      "consistency_loss_weight": 0.41127983418522873,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.07871340115865072
  },
  {
    "run_id": 2,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 25,
      "batch_size": 128,
      "lr": 0.0013987770280858801,
      "weight_decay": 0.00024329582739094797,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.11567722294091715,
      "mastery_performance_loss_weight": 1.909299148337501,
      "gain_performance_loss_weight": 1.0439359127868517,
      "monotonicity_loss_weight": 0.05002536282630153,
      "sparsity_loss_weight": 0.13683309414101352,
      "consistency_loss_weight": 0.20468586340999592,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.08143827517827353
  },
  {
    "run_id": 4,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 25,
      "batch_size": 128,
      "lr": 0.0007380621810127295,
      "weight_decay": 0.0001805612082350496,
      "num_encoder_blocks": 5,
      "d_ff": 768,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.22979486690065473,
      "mastery_performance_loss_weight": 1.118753032981737,
      "gain_performance_loss_weight": 1.0840639120340272,
      "monotonicity_loss_weight": 0.16864456396962618,
      "sparsity_loss_weight": 0.4664360740759502,
      "consistency_loss_weight": 0.25074807866656873,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.08507649103800456
  },
  {
    "run_id": 3,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 30,
      "batch_size": 32,
      "lr": 0.0017441629445973117,
      "weight_decay": 5.303329897071189e-05,
      "num_encoder_blocks": 5,
      "d_ff": 1024,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.16549195387986643,
      "mastery_performance_loss_weight": 1.1220858161859661,
      "gain_performance_loss_weight": 1.711831764189389,
      "monotonicity_loss_weight": 0.0770310715046492,
      "sparsity_loss_weight": 0.2527416564885248,
      "consistency_loss_weight": 0.5977673856351051,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.0871168573697408
  },
  {
    "run_id": 5,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 30,
      "batch_size": 128,
      "lr": 0.0007491969196185413,
      "weight_decay": 5.531494017117134e-05,
      "num_encoder_blocks": 6,
      "d_ff": 1024,
      "d_model": 512,
      "n_heads": 12,
      "dropout": 0.25038530976214857,
      "mastery_performance_loss_weight": 1.7520350158208626,
      "gain_performance_loss_weight": 1.0735262781177932,
      "monotonicity_loss_weight": 0.09728930336291174,
      "sparsity_loss_weight": 0.31624835488040215,
      "consistency_loss_weight": 0.5235716733056215,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.08786049683888754
  },
  {
    "run_id": 7,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 25,
      "batch_size": 128,
      "lr": 0.00195252030239113,
      "weight_decay": 0.0002907099049137498,
      "num_encoder_blocks": 5,
      "d_ff": 768,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.18993213369289885,
      "mastery_performance_loss_weight": 2.1354833576687655,
      "gain_performance_loss_weight": 1.8421130335145626,
      "monotonicity_loss_weight": 0.27129347360497175,
      "sparsity_loss_weight": 0.4758840459936132,
      "consistency_loss_weight": 0.5533474071771147,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.07737859487533569
  },
  {
    "run_id": 8,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 30,
      "batch_size": 64,
      "lr": 0.0006534211197023528,
      "weight_decay": 0.0004537162862824147,
      "num_encoder_blocks": 5,
      "d_ff": 896,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.25973268866485133,
      "mastery_performance_loss_weight": 1.6642852314913623,
      "gain_performance_loss_weight": 1.1035813003102857,
      "monotonicity_loss_weight": 0.062298097956741225,
      "sparsity_loss_weight": 0.162123724053625,
      "consistency_loss_weight": 0.2472238828431182,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.07667546272277832
  },
  {
    "run_id": 6,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0007521861075661785,
      "weight_decay": 0.00038897766077912606,
      "num_encoder_blocks": 5,
      "d_ff": 768,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.15860920034246678,
      "mastery_performance_loss_weight": 1.3185104599474533,
      "gain_performance_loss_weight": 1.5405778093645588,
      "monotonicity_loss_weight": 0.20374595760726671,
      "sparsity_loss_weight": 0.32142871235243714,
      "consistency_loss_weight": 0.2608871789642416,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.08306376536687216
  },
  {
    "run_id": 10,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 25,
      "batch_size": 32,
      "lr": 0.0006824497709517657,
      "weight_decay": 0.00028574452956692167,
      "num_encoder_blocks": 6,
      "d_ff": 768,
      "d_model": 384,
      "n_heads": 4,
      "dropout": 0.15606666188478652,
      "mastery_performance_loss_weight": 1.7071747819800211,
      "gain_performance_loss_weight": 1.8295867753850221,
      "monotonicity_loss_weight": 0.15185498532476077,
      "sparsity_loss_weight": 0.12271326441982514,
      "consistency_loss_weight": 0.3546299692020907,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.07709842125574748
  },
  {
    "run_id": 9,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 30,
      "batch_size": 128,
      "lr": 0.0013117823734992956,
      "weight_decay": 5.865646486554314e-05,
      "num_encoder_blocks": 5,
      "d_ff": 1024,
      "d_model": 384,
      "n_heads": 8,
      "dropout": 0.17571710300919285,
      "mastery_performance_loss_weight": 1.261510495324747,
      "gain_performance_loss_weight": 1.8983522152629988,
      "monotonicity_loss_weight": 0.10767485349835663,
      "sparsity_loss_weight": 0.12005113481603474,
      "consistency_loss_weight": 0.29676492723465475,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.07948008378346762
  },
  {
    "run_id": 11,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 20,
      "batch_size": 32,
      "lr": 0.0008583244108071997,
      "weight_decay": 7.936519451276459e-05,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.24276871280234769,
      "mastery_performance_loss_weight": 1.80276582969348,
      "gain_performance_loss_weight": 1.761366892534174,
      "monotonicity_loss_weight": 0.27297556235577003,
      "sparsity_loss_weight": 0.25768658350935414,
      "consistency_loss_weight": 0.4786266961589077,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.0812459111213684
  },
  {
    "run_id": 12,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 25,
      "batch_size": 128,
      "lr": 0.0006832118579034588,
      "weight_decay": 5.5115795036999176e-05,
      "num_encoder_blocks": 4,
      "d_ff": 768,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.16412452086273527,
      "mastery_performance_loss_weight": 1.8923899411412703,
      "gain_performance_loss_weight": 1.8702674641415065,
      "monotonicity_loss_weight": 0.13587143607818786,
      "sparsity_loss_weight": 0.41143550485667724,
      "consistency_loss_weight": 0.5681999119154797,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.07867763042449952
  },
  {
    "run_id": 15,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0013109237384734307,
      "weight_decay": 0.00042126467010323486,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.1939240336836,
      "mastery_performance_loss_weight": 2.1647780201561506,
      "gain_performance_loss_weight": 1.968896983073483,
      "monotonicity_loss_weight": 0.1827153883098871,
      "sparsity_loss_weight": 0.32328950506448406,
      "consistency_loss_weight": 0.513879248024796,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.0813539703687032
  },
  {
    "run_id": 13,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 30,
      "batch_size": 128,
      "lr": 0.00195808368812181,
      "weight_decay": 5.041197521882892e-05,
      "num_encoder_blocks": 5,
      "d_ff": 1024,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.27909419226893356,
      "mastery_performance_loss_weight": 2.125192298716554,
      "gain_performance_loss_weight": 2.1636948774448626,
      "monotonicity_loss_weight": 0.057465988273039656,
      "sparsity_loss_weight": 0.19393015577450248,
      "consistency_loss_weight": 0.3455632839012394,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.08621605237325032
  },
  {
    "run_id": 14,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0007735190154191456,
      "weight_decay": 8.002253402772505e-05,
      "num_encoder_blocks": 4,
      "d_ff": 896,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.23633291775801965,
      "mastery_performance_loss_weight": 1.000103386573344,
      "gain_performance_loss_weight": 2.0573515933483764,
      "monotonicity_loss_weight": 0.0710412717680889,
      "sparsity_loss_weight": 0.18018413920505152,
      "consistency_loss_weight": 0.25076658683651876,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--d_model D_MODEL]\n             ",
    "duration_minutes": 0.0831171711285909
  }
]