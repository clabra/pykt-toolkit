[
  {
    "run_id": 2,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 30,
      "batch_size": 128,
      "lr": 0.001312212653451868,
      "weight_decay": 0.00010890784579480682,
      "num_encoder_blocks": 5,
      "d_ff": 768,
      "d_model": 384,
      "n_heads": 4,
      "dropout": 0.1788257596020098,
      "mastery_performance_loss_weight": 1.9699797776271022,
      "gain_performance_loss_weight": 1.385761681216205,
      "monotonicity_loss_weight": 0.06806805991025909,
      "sparsity_loss_weight": 0.3759424644795851,
      "consistency_loss_weight": 0.21794827379862955,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.07832364638646444
  },
  {
    "run_id": 4,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 25,
      "batch_size": 128,
      "lr": 0.0017408408447751728,
      "weight_decay": 0.0004498304826481842,
      "num_encoder_blocks": 4,
      "d_ff": 896,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.280824328034209,
      "mastery_performance_loss_weight": 1.3415609468956124,
      "gain_performance_loss_weight": 2.3115199862413953,
      "monotonicity_loss_weight": 0.061573344633640184,
      "sparsity_loss_weight": 0.15442021205188108,
      "consistency_loss_weight": 0.4882340343423495,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08106091419855753
  },
  {
    "run_id": 3,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 25,
      "batch_size": 32,
      "lr": 0.0009603250115464906,
      "weight_decay": 0.00044221401675726573,
      "num_encoder_blocks": 4,
      "d_ff": 1024,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.2935737978593194,
      "mastery_performance_loss_weight": 2.282450373267948,
      "gain_performance_loss_weight": 1.3868973050991542,
      "monotonicity_loss_weight": 0.09385418419374768,
      "sparsity_loss_weight": 0.43178860067239433,
      "consistency_loss_weight": 0.525565605228576,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08431175947189332
  },
  {
    "run_id": 5,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 20,
      "batch_size": 32,
      "lr": 0.0005422278708173611,
      "weight_decay": 6.582997980484522e-05,
      "num_encoder_blocks": 5,
      "d_ff": 896,
      "d_model": 512,
      "n_heads": 4,
      "dropout": 0.27553694825320774,
      "mastery_performance_loss_weight": 2.2012998978202445,
      "gain_performance_loss_weight": 1.8707848056512306,
      "monotonicity_loss_weight": 0.06286341566415844,
      "sparsity_loss_weight": 0.10432693585767945,
      "consistency_loss_weight": 0.22480128073227648,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08434223333994548
  },
  {
    "run_id": 1,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 30,
      "batch_size": 32,
      "lr": 0.0009503493848334949,
      "weight_decay": 0.0002102806819003874,
      "num_encoder_blocks": 4,
      "d_ff": 1024,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.14353411363690063,
      "mastery_performance_loss_weight": 2.2801451642628967,
      "gain_performance_loss_weight": 2.410522264135357,
      "monotonicity_loss_weight": 0.12356190411265384,
      "sparsity_loss_weight": 0.1476687125401291,
      "consistency_loss_weight": 0.535275663743221,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08688656489054362
  },
  {
    "run_id": 6,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 20,
      "batch_size": 128,
      "lr": 0.0011171254502505559,
      "weight_decay": 0.00018987942849378497,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 256,
      "n_heads": 12,
      "dropout": 0.10671061780232403,
      "mastery_performance_loss_weight": 2.1999726259130004,
      "gain_performance_loss_weight": 1.201482906305516,
      "monotonicity_loss_weight": 0.25714292826193963,
      "sparsity_loss_weight": 0.2973874911050859,
      "consistency_loss_weight": 0.4293353115981705,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.07668871482213338
  },
  {
    "run_id": 7,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 30,
      "batch_size": 32,
      "lr": 0.0007677511775582458,
      "weight_decay": 0.00020305189992815572,
      "num_encoder_blocks": 6,
      "d_ff": 640,
      "d_model": 512,
      "n_heads": 12,
      "dropout": 0.11808838713810131,
      "mastery_performance_loss_weight": 2.0078760222204517,
      "gain_performance_loss_weight": 1.611515278337323,
      "monotonicity_loss_weight": 0.0728071050925911,
      "sparsity_loss_weight": 0.15388979538743977,
      "consistency_loss_weight": 0.38195621543322256,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.07752824227015177
  },
  {
    "run_id": 9,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 25,
      "batch_size": 64,
      "lr": 0.0012051378168448435,
      "weight_decay": 0.00015363121305278545,
      "num_encoder_blocks": 6,
      "d_ff": 768,
      "d_model": 512,
      "n_heads": 4,
      "dropout": 0.22298575712853574,
      "mastery_performance_loss_weight": 1.4241700007166411,
      "gain_performance_loss_weight": 1.1778548365738604,
      "monotonicity_loss_weight": 0.2073157510821489,
      "sparsity_loss_weight": 0.3553155629916479,
      "consistency_loss_weight": 0.5046464711797155,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08156305154164632
  },
  {
    "run_id": 10,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0006743357014972625,
      "weight_decay": 0.00014263676053521314,
      "num_encoder_blocks": 5,
      "d_ff": 896,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.18702895869918534,
      "mastery_performance_loss_weight": 2.0426576644251306,
      "gain_performance_loss_weight": 2.1513155523228447,
      "monotonicity_loss_weight": 0.19586607416990115,
      "sparsity_loss_weight": 0.39165603844632746,
      "consistency_loss_weight": 0.4841141253209796,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.07992130120595296
  },
  {
    "run_id": 8,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 30,
      "batch_size": 32,
      "lr": 0.0005041574434259851,
      "weight_decay": 0.00032291411855445607,
      "num_encoder_blocks": 5,
      "d_ff": 1024,
      "d_model": 384,
      "n_heads": 4,
      "dropout": 0.10066233392893723,
      "mastery_performance_loss_weight": 1.679449002751045,
      "gain_performance_loss_weight": 1.7489428043116542,
      "monotonicity_loss_weight": 0.09742599119010718,
      "sparsity_loss_weight": 0.10788542553548455,
      "consistency_loss_weight": 0.2529001631714939,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08493733008702596
  },
  {
    "run_id": 12,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 20,
      "batch_size": 32,
      "lr": 0.0007973825622754713,
      "weight_decay": 0.0002057036351311951,
      "num_encoder_blocks": 5,
      "d_ff": 768,
      "d_model": 384,
      "n_heads": 4,
      "dropout": 0.18830632952980608,
      "mastery_performance_loss_weight": 2.3524584390861305,
      "gain_performance_loss_weight": 1.0210329225369614,
      "monotonicity_loss_weight": 0.09144772120362445,
      "sparsity_loss_weight": 0.22142800959311248,
      "consistency_loss_weight": 0.532491641194958,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08032662073771159
  },
  {
    "run_id": 11,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 25,
      "batch_size": 32,
      "lr": 0.0006706445175722379,
      "weight_decay": 0.0002535634694890623,
      "num_encoder_blocks": 5,
      "d_ff": 896,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.19428031133156792,
      "mastery_performance_loss_weight": 1.3682719121093676,
      "gain_performance_loss_weight": 1.1242484503728314,
      "monotonicity_loss_weight": 0.08059279356653794,
      "sparsity_loss_weight": 0.46888163407205463,
      "consistency_loss_weight": 0.23688890891267966,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08607068061828613
  },
  {
    "run_id": 14,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 30,
      "batch_size": 64,
      "lr": 0.000777816985055388,
      "weight_decay": 0.0001381536212777735,
      "num_encoder_blocks": 4,
      "d_ff": 640,
      "d_model": 384,
      "n_heads": 4,
      "dropout": 0.20458843723429795,
      "mastery_performance_loss_weight": 1.2426092533247086,
      "gain_performance_loss_weight": 1.4749298048165327,
      "monotonicity_loss_weight": 0.22483331539736812,
      "sparsity_loss_weight": 0.2505836407029828,
      "consistency_loss_weight": 0.405448312351444,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.07815206448237101
  },
  {
    "run_id": 13,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 30,
      "batch_size": 64,
      "lr": 0.0006263263974156172,
      "weight_decay": 0.0003946089265388042,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 384,
      "n_heads": 8,
      "dropout": 0.22796495228050034,
      "mastery_performance_loss_weight": 1.3970733174978314,
      "gain_performance_loss_weight": 1.8389079670521582,
      "monotonicity_loss_weight": 0.24906345531935242,
      "sparsity_loss_weight": 0.2870158384279472,
      "consistency_loss_weight": 0.568568408497501,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08149504661560059
  },
  {
    "run_id": 15,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 30,
      "batch_size": 64,
      "lr": 0.0019797220089461938,
      "weight_decay": 0.0001896367490901188,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.22835504834890272,
      "mastery_performance_loss_weight": 1.2796403515087278,
      "gain_performance_loss_weight": 1.209392713116922,
      "monotonicity_loss_weight": 0.13882910001922155,
      "sparsity_loss_weight": 0.40832122586418784,
      "consistency_loss_weight": 0.24647640980231844,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.07984371185302734
  }
]