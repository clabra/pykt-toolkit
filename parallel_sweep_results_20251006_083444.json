[
  {
    "run_id": 2,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 30,
      "batch_size": 128,
      "lr": 0.0005528765989206124,
      "weight_decay": 0.00011592257384423254,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 384,
      "n_heads": 12,
      "dropout": 0.17295394587886453,
      "mastery_performance_loss_weight": 2.305055582969387,
      "gain_performance_loss_weight": 1.0550475364181515,
      "monotonicity_loss_weight": 0.19602863250761932,
      "sparsity_loss_weight": 0.2934961271524044,
      "consistency_loss_weight": 0.5218890585019864,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08001658121744791
  },
  {
    "run_id": 4,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0015375944745179388,
      "weight_decay": 0.00031249580696292767,
      "num_encoder_blocks": 4,
      "d_ff": 896,
      "d_model": 384,
      "n_heads": 4,
      "dropout": 0.15259393406662064,
      "mastery_performance_loss_weight": 1.425881353154753,
      "gain_performance_loss_weight": 2.31557335377557,
      "monotonicity_loss_weight": 0.09400906192726756,
      "sparsity_loss_weight": 0.44420083582546677,
      "consistency_loss_weight": 0.25783729739406086,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08002088069915772
  },
  {
    "run_id": 1,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 20,
      "batch_size": 128,
      "lr": 0.001419266648950283,
      "weight_decay": 0.00022367438699746325,
      "num_encoder_blocks": 5,
      "d_ff": 896,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.1462356505291162,
      "mastery_performance_loss_weight": 1.5104456834195992,
      "gain_performance_loss_weight": 1.6888773233321883,
      "monotonicity_loss_weight": 0.09679638803130254,
      "sparsity_loss_weight": 0.19995160267881534,
      "consistency_loss_weight": 0.4611063464033007,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08185941378275553
  },
  {
    "run_id": 5,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 20,
      "batch_size": 32,
      "lr": 0.000996390046253939,
      "weight_decay": 0.000176080719156928,
      "num_encoder_blocks": 6,
      "d_ff": 896,
      "d_model": 384,
      "n_heads": 8,
      "dropout": 0.2885176582884904,
      "mastery_performance_loss_weight": 2.254778123882459,
      "gain_performance_loss_weight": 2.1763711718248877,
      "monotonicity_loss_weight": 0.14507821048439318,
      "sparsity_loss_weight": 0.4735304926680476,
      "consistency_loss_weight": 0.5298586744071234,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08250159025192261
  },
  {
    "run_id": 3,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 25,
      "batch_size": 32,
      "lr": 0.0005497198962859781,
      "weight_decay": 9.623238155181508e-05,
      "num_encoder_blocks": 4,
      "d_ff": 640,
      "d_model": 512,
      "n_heads": 8,
      "dropout": 0.25725049513729825,
      "mastery_performance_loss_weight": 2.483926731513109,
      "gain_performance_loss_weight": 1.2738697166831954,
      "monotonicity_loss_weight": 0.10374088961298651,
      "sparsity_loss_weight": 0.16439049210521595,
      "consistency_loss_weight": 0.4665205875182828,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08252619902292888
  },
  {
    "run_id": 7,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 25,
      "batch_size": 32,
      "lr": 0.0007863505980728292,
      "weight_decay": 0.0001985212358261601,
      "num_encoder_blocks": 4,
      "d_ff": 1024,
      "d_model": 256,
      "n_heads": 4,
      "dropout": 0.2800772619532599,
      "mastery_performance_loss_weight": 2.021939415926871,
      "gain_performance_loss_weight": 1.8782629755192364,
      "monotonicity_loss_weight": 0.055092815060446845,
      "sparsity_loss_weight": 0.4510305090394289,
      "consistency_loss_weight": 0.41649600531281217,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08469825188318889
  },
  {
    "run_id": 6,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 30,
      "batch_size": 32,
      "lr": 0.001686532166237131,
      "weight_decay": 0.000354664643725005,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.12944892044109182,
      "mastery_performance_loss_weight": 1.075184777466479,
      "gain_performance_loss_weight": 2.0655926908557545,
      "monotonicity_loss_weight": 0.29164903366771044,
      "sparsity_loss_weight": 0.2811847110849106,
      "consistency_loss_weight": 0.5018728405314975,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08591115872065226
  },
  {
    "run_id": 9,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0012465436690990807,
      "weight_decay": 5.315873904809671e-05,
      "num_encoder_blocks": 5,
      "d_ff": 1024,
      "d_model": 512,
      "n_heads": 12,
      "dropout": 0.12638306698292814,
      "mastery_performance_loss_weight": 1.5414433015048603,
      "gain_performance_loss_weight": 2.076853167041988,
      "monotonicity_loss_weight": 0.2901841029105166,
      "sparsity_loss_weight": 0.29345801211342337,
      "consistency_loss_weight": 0.44022071681105956,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08537903229395548
  },
  {
    "run_id": 10,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 25,
      "batch_size": 32,
      "lr": 0.0006295574115398285,
      "weight_decay": 0.00011287106842408031,
      "num_encoder_blocks": 4,
      "d_ff": 640,
      "d_model": 512,
      "n_heads": 12,
      "dropout": 0.26276443893985474,
      "mastery_performance_loss_weight": 2.3317547681419875,
      "gain_performance_loss_weight": 1.6673562075784956,
      "monotonicity_loss_weight": 0.20139764326244408,
      "sparsity_loss_weight": 0.2835478137780424,
      "consistency_loss_weight": 0.5249297656789051,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08552063703536987
  },
  {
    "run_id": 8,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.0016577935360601957,
      "weight_decay": 8.786977337139399e-05,
      "num_encoder_blocks": 4,
      "d_ff": 1024,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.21713063062703364,
      "mastery_performance_loss_weight": 2.396597467597427,
      "gain_performance_loss_weight": 1.1678776402730167,
      "monotonicity_loss_weight": 0.2462134153205559,
      "sparsity_loss_weight": 0.24115562405084448,
      "consistency_loss_weight": 0.5351517388026925,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08729557593663534
  },
  {
    "run_id": 11,
    "gpu_id": 0,
    "parameters": {
      "gpu_id": 0,
      "epochs": 30,
      "batch_size": 128,
      "lr": 0.0019269326495670411,
      "weight_decay": 9.897507900167886e-05,
      "num_encoder_blocks": 4,
      "d_ff": 1024,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.12782470194365186,
      "mastery_performance_loss_weight": 1.8100805249637455,
      "gain_performance_loss_weight": 2.0361473547531457,
      "monotonicity_loss_weight": 0.1761410828324811,
      "sparsity_loss_weight": 0.4678338533395078,
      "consistency_loss_weight": 0.3475539801545998,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08048071066538492
  },
  {
    "run_id": 15,
    "gpu_id": 4,
    "parameters": {
      "gpu_id": 4,
      "epochs": 25,
      "batch_size": 32,
      "lr": 0.0005304844535261456,
      "weight_decay": 8.112030903698796e-05,
      "num_encoder_blocks": 5,
      "d_ff": 640,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.2392301652271689,
      "mastery_performance_loss_weight": 1.2800261180898502,
      "gain_performance_loss_weight": 2.0828398097362397,
      "monotonicity_loss_weight": 0.11118977237535345,
      "sparsity_loss_weight": 0.31677394374952167,
      "consistency_loss_weight": 0.5329731918032707,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.07725867827733358
  },
  {
    "run_id": 12,
    "gpu_id": 1,
    "parameters": {
      "gpu_id": 1,
      "epochs": 25,
      "batch_size": 128,
      "lr": 0.0010900141696379682,
      "weight_decay": 0.00013435441037990497,
      "num_encoder_blocks": 4,
      "d_ff": 896,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.19494049519604345,
      "mastery_performance_loss_weight": 1.2569305671845221,
      "gain_performance_loss_weight": 1.9229104523330753,
      "monotonicity_loss_weight": 0.1354445272032101,
      "sparsity_loss_weight": 0.27156678010368596,
      "consistency_loss_weight": 0.5426954842201756,
      "patience": 10,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.0813077449798584
  },
  {
    "run_id": 13,
    "gpu_id": 2,
    "parameters": {
      "gpu_id": 2,
      "epochs": 20,
      "batch_size": 64,
      "lr": 0.001468197134653881,
      "weight_decay": 9.465152578379611e-05,
      "num_encoder_blocks": 5,
      "d_ff": 1024,
      "d_model": 256,
      "n_heads": 8,
      "dropout": 0.27468204343246894,
      "mastery_performance_loss_weight": 1.685801334199147,
      "gain_performance_loss_weight": 1.3749288165002447,
      "monotonicity_loss_weight": 0.28823886530932996,
      "sparsity_loss_weight": 0.2899107734400711,
      "consistency_loss_weight": 0.3820627730379702,
      "patience": 15,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08529365062713623
  },
  {
    "run_id": 14,
    "gpu_id": 3,
    "parameters": {
      "gpu_id": 3,
      "epochs": 30,
      "batch_size": 32,
      "lr": 0.001527087176156128,
      "weight_decay": 0.0003149027213802977,
      "num_encoder_blocks": 4,
      "d_ff": 896,
      "d_model": 256,
      "n_heads": 12,
      "dropout": 0.27569855406316646,
      "mastery_performance_loss_weight": 1.1841265343352245,
      "gain_performance_loss_weight": 2.343551806457346,
      "monotonicity_loss_weight": 0.14941269754967146,
      "sparsity_loss_weight": 0.21593788145419485,
      "consistency_loss_weight": 0.5041161470882431,
      "patience": 20,
      "enhanced_constraints": true,
      "dataset": "assist2015",
      "fold": 0,
      "use_wandb": true
    },
    "status": "failed",
    "error": "usage: train_cumulative_mastery_full.py [-h] [--epochs EPOCHS]\n                                        [--batch_size BATCH_SIZE] [--lr LR]\n                                        [--weight_decay WEIGHT_DECAY]\n                                        [--patience PATIENCE]\n                                        [--enhanced_constraints ENHANCED_CONSTRAINTS]\n                                        [--monitor_freq MONITOR_FREQ]\n                                        [--dataset DATASET] [--fold FOLD]",
    "duration_minutes": 0.08539455731709798
  }
]